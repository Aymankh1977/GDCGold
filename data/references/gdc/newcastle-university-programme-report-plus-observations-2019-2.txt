Education Quality Assurance Inspection Report
Education
Provider/Awarding
Body
Newcastle University

Outcome of Inspection

Programme/Award

Inspection Date

Bachelor of Dental
Surgery (BDS)

9 May 2019

Recommended that the BDS
continues to be sufficient for the
graduating cohort to register as
dentist.

1

*Full details of the inspection process can be found in the annex*
Inspection summary
Remit and purpose of inspection:

Learning Outcomes:

Inspection referencing the Standards for
Education to determine approval of the
award for the purpose of registration with
the GDC as a dentist.
Risk based: focused on Requirements 4, 9,
11, 13, 15 and 19
Preparing for Practice (Dentist)

Programme inspection date:

9 May 2019

Inspection team:

Gail Mortimer (Chair and Non-registrant
Member)
Sarah Balian (DCP Member)
Thomas Addison (Dentist Member)
Martin McElvanna (GDC Education & Quality
Assurance Officer)
Krutika Patel (GDC Quality Assurance
Officer)
Amy Mullins-Downes (GDC Quality
Assurance Manager)

The BDS inspection undertaken at Newcastle University was a risk-based inspection looking
at specific areas of focus identified by the GDC’s Education & Quality Assurance team in
2018. Information considered when identifying potential or actual risks included annual
monitoring returns, previous inspection reports (and progress against any actions) and
responses to wider recommendations in the GDC Annual Review of Education.
The inspection focused on Requirements 4, 9, 11, 13, 15 and 19 and specific areas within
those Requirements which are detailed below.
The inspection panel, comprising of GDC education associates, were grateful for the
documentation received in advance of the inspection. Having reviewed this, the panel sought
further documents and an additional comprehensive set was provided. Requests for
additional information during the inspection were provided quickly.
The panel was impressed by the robust management structure evident within the School,
together with a cohesive team approach amongst all of the staff involved in the delivery of
the learning outcomes, assessment and administration of the programme. The School has a
culture of developing staff from within.
The team considered that the management of outreach was good and that outreach
placements allowed students to gain a broad range of experience in a number of clinical
settings.
The associates were impressed with the pastoral care of students. We noted positive
feedback from student representatives in terms of support, supervision and action. Students
were also positive about staff, indicating there is a good relationship with them.

2

The panel considered the School’s approach to assessment as both innovative and
progressive. As students move through the programme stages their progression can be
clearly seen and the team was satisfied that the students were fit to practise as safe
beginners upon graduation.
The School is also to be commended for having an open dialogue with external partners and
the Health Education England working across the North East and Cumbria.
Overall, the team had no major concerns with the programme and agreed it was well
organised and ensures a thorough assessment of students across the learning outcomes
contained within the GDC publication ‘Preparing for Practice’.
The panel wishes to thank the staff, students, and external stakeholders involved with the
BDS programme for their co-operation and assistance with the inspection.

3

Background and overview of Qualification
Annual intake
Programme duration
Format of programme

71 students
188 weeks over 5 years
Stage 1
Orientation and Study Skills
Anatomy of the Head and Neck
Cell Biology
Interpersonal Skills and Shadowing
Introduction to Dentistry
Neurobiology
Dental Physiology
Metabolism & Homeostasis
Stage 2
Craniofacial and Tooth Biology
Behavioural and Social Science for
Dentists
Basic Pharmacology
Dental Materials Science
Microbiology for Dentistry
Immunology and Healthcare
Nutrition and Diet Oral Environment
Key Clinical Skills
Stage 3
Clinical Introduction Course
Applied Anatomy
Dental Materials Science
Dental Public Health
Human Diseases
Oral Diseases
Clinical Skills courses in Restorative
Dentistry, and Orthodontics
Clinical attachments with associated
lectures and seminars in Restorative
Dentistry, Paediatric Dentistry,
Primary Care Outreach (Oral Health
Education), Oral Surgery, Dental
Emergency Clinic and Radiology
Stage 4
Dental Public Health
Dental Sedation
Human Diseases
Oral Diseases
Clinical Skills courses in Restorative
Dentistry and Oral Surgery
Clinical attachments with associated
lectures and seminars in Restorative
Dentistry (including Interprofessional
Clinic), Paediatric Dentistry, Primary
Care Outreach, and Oral Surgery
Stage 5
Current Opinion in Dentistry
4

Dental Public Health
Gerodontology
Oral Diseases
Clinical attachments with associated
lectures and seminars in Restorative
Dentistry, Paediatric Dentistry,
Primary Care Outreach, Dental
Emergency Clinic and Oral and
Maxillofacial Surgery
Stages 1- 5
A vertically integrated course on
Professionalism and Personal &
Professional Development runs
through all stages of the programme.
Number of providers delivering the
programme

1 – Newcastle University

5

Outcome of relevant Requirements1
Standard One
1

Met

2

Met

3

Met

4

Met

5

Met

6

Met

7

Met

8

Met
Standard Two

9

Met

10

Met

11

Met

12

Met
Standard Three

13

Met

14

Met

15

Met

16

Met

17

Met

18

Met

19

Met

20

Met

21

Met

All Requirements within the Standards for Education are applicable for all programmes unless otherwise
stated. Specific requirements will be examined through inspection activity and will be identified via risk
analysis processes or due to current thematic reviews.
1

6

Standard 1 – Protecting patients
Providers must be aware of their duty to protect the public. Providers must ensure that
patient safety is paramount and care of patients is of an appropriate standard. Any risk
to the safety of patients and their care by students must be minimised.
Requirement 1: Students must provide patient care only when they have demonstrated
adequate knowledge and skills. For clinical procedures, the student should be
assessed as competent in the relevant skills at the levels required in the pre-clinical
environments prior to treating patients. (Requirement Met)
Requirement 2: Providers must have systems in place to inform patients that they may
be treated by students and the possible implications of this. Patient agreement to
treatment by a student must be obtained and recorded prior to treatment commencing.
(Requirement Met)
Requirement 3: Students must only provide patient care in an environment which is
safe and appropriate. The provider must comply with relevant legislation and
requirements regarding patient care, including equality and diversity, wherever
treatment takes place. (Requirement Met)
Requirement 4: When providing patient care and services, providers must ensure that
students are supervised appropriately according to the activity and the student’s stage
of development. (Requirement Met)
Under this Requirement, the panel was tasked with also looking at staffing levels and the
supervision of students and whether this has any impact on how this Requirement is met.
The School indicated that there are always challenges with staffing and in particular with
recruitment of clinical academics. However, they explained that in the event of School
vacancies at lecturer level, it is usually possible to recruit from within the Clinical Fellow cohort.
The senior academic team is composed of a high number of Newcastle graduates promoting
the ethos of the school and the number of Clinical Fellows trained and retained is highly
commendable. The School is confident of their solid network involving all teams with a strong
ethos of multi-disciplinary collaboration. The panel considered that there were good
communication streams within the School.
The School explained that students undertake clinical activity in their respective year cohorts,
with suitably allocated supervisors who have appropriate experience. The team acknowledged
that there are good supervision levels within clinics. Continuity of staffing is maintained to
ensure a consistent teaching experience. The School explained that when determining the
appropriate staff to student ratio, they are mindful of the student’s stage of development and
area of clinical discipline. However, their main focus is to ensure the ratios allow for high
quality teaching and tailored feedback. For example, at the start of clinical placement in stage
3, students are supervised in a 1:4 ratio in the paediatric, conservation, periodontology and
prosthodontics clinics. In oral surgery, sedation and dental emergencies clinics, students are
supervised on a 1:1 ratio for exodontia.
In the event of staff shortages, the panel noted there are strong contingency plans in place to
relocate staff from other clinics if possible so that these ratios are maintained. As a last resort,
if ratios cannot be maintained, clinics are cancelled in the interests of patient safety. Clinical
Teaching Leads arrange staff rotas and in the event of absence, have the responsibility to
maintain patient safety and student educational experience in line with the School’s guidance
documents.
7

Regarding succession planning, the responsibility lies with the School’s Senior Management
Team consisting of the Head of School, the Director of Dental Education, the Director of
Research and the School Manager. This is outlined in the School’s Strategic Review document
which also details objectives that were created and specific actions to be taken.
Finally, the associates noted that nursing support was good. Qualified nurses have access to
the School’s electronic database called ‘iDentity’ where they can provide feedback on students.
There are two or three chairs per nurse so students know who they will be working with. Crossinfection teaching and assessment at outreach is also delivered by nurses.
Requirement 5: Supervisors must be appropriately qualified and trained. This should
include training in equality and diversity legislation relevant for the role. Clinical
supervisors must have appropriate general or specialist registration with a UK
regulatory body. (Requirement Met)
Requirement 6: Providers must ensure that students and all those involved in the
delivery of education and training are aware of their obligation to raise concerns if they
identify any risks to patient safety and the need for candour when things go wrong.
Providers should publish policies so that it is clear to all parties how concerns should
be raised and how these concerns will be acted upon. Providers must support those
who do raise concerns and provide assurance that staff and students will not be
penalised for doing so. (Requirement Met)
Requirement 7: Systems must be in place to identify and record issues that may affect
patient safety. Should a patient safety issue arise, appropriate action must be taken by
the provider and where necessary the relevant regulatory body should be notified.
(Requirement Met)
Requirement 8: Providers must have a student fitness to practise policy and apply as
required. The content and significance of the student fitness to practise procedures
must be conveyed to students and aligned to GDC Student Fitness to Practise
Guidance. Staff involved in the delivery of the programme should be familiar with the
GDC Student Fitness to Practise Guidance. Providers must also ensure that the GDC’s
Standard for the Dental Team are embedded within student training. (Requirement Met)

Standard 2 – Quality evaluation and review of the programme
The provider must have in place effective policy and procedures for the monitoring and
review of the programme.
Requirement 9: The provider must have a framework in place that details how it
manages the quality of the programme which includes making appropriate changes to
ensure the curriculum continues to map across to the latest GDC outcomes and adapts
to changing legislation and external guidance. There must be a clear statement about
where responsibility lies for this function. (Requirement Met)
Under this Requirement, the panel was also tasked with looking at staffing levels and whether
this has any impact on how this Requirement is met.
Before the inspection, the panel were furnished with a range of documents to illustrate the
complex quality assurance framework within which the School operates. There are a variety of
mechanisms, processes and committees that underpin the operation of the framework and
these are explained in the University’s Quality and Standards Handbook. These ensure that
the quality of the programme is being monitored and improved at various levels, such as
School, Faculty and University level. At the inspection, the School’s senior team
8

comprehensively explained this framework further. Overall responsibility for the School’s
framework lies with the Head of School, supported by the School of Dental Sciences Executive
committee. However, in terms of day to day management of the framework, that responsibility
is delegated to the Director of Dental Education. Responsibility for longer term succession
planning falls to the School’s Senior Management Team and is recorded in the School’s
comprehensive annual Strategic Review.
The team learnt that the responsibility for quality assuring academic standards and teaching
lies initially with the University Education Committee (UEC), which develops and oversees the
policies and procedures to underpin these. At Faculty level, the Faculty Education Committee
(FEC) ensures that the UEC’s University’s policies and procedures are effectively
implemented.
The panel also heard about the operation of the Board of Studies (BoS) and how it plays a vital
role in overseeing and monitoring the quality evaluation and assurance processes. Chaired by
the Director of Dental Education, the BoS meets once a month to review various reports from
the Directors of Examinations and Assessment, Progression and Student Support, Academic
Studies and Clinical Studies. It also receives reports from the Student Staff Committee (SSC)
and student representatives are members of and attend the Board of Studies. Reports include
suggestions for changes and external examiner feedback reports. The outcome of the BoS
meetings are reported to the School Executive who may request that the BoS take follow-up
actions. Although the School does not have a risk register as such, the BoS identifies and flags
up any risks to the programme, such as the retirement of key staff members. The team had
sight of the BoS Action Minutes and agendas to illustrate its operational role.
Regarding assessment mapping to the latest GDC outcomes, the panel heard that the School
uses a red, amber and green rating system, presenting as a minimum of three opportunities for
mapping attainment against each of the learning outcomes. The team also heard that the BoS
has an added responsibility for ensuring that all assessments within the programme are
mapped against the learning outcomes. We saw evidence that proposed changes to the
Gerodontology course had been documented and the potential impact of such changes on the
attainment of the learning outcomes clearly outlined. At the inspection, the School confirmed
that they are currently mapping learning outcomes to the level of exam questions.
Regarding changes to the programme, the panel observed that recommendations for changes
are initially considered by the relevant School committee before being referred to BoS for initial
approval. Major changes must be escalated to Faculty level for final approval. The panel saw
several examples of major changes made to the programme since the last GDC inspection,
resulting from a widescale review of processes. Following external consultation, there have
been changes to the sign-up process which now takes into account both knowledge and
clinical skills based assessments: 23 defined In-Course Clinical Competency Assessments
(INCCA), Restorative and Paediatric Case Portfolios, Medical Emergencies training, Dental
Public Heath Assessment, Professionalism (In-course) essay, Radiology (IRMER) and Oral
Diseases Clinical Slides assessments. This process also considers any outstanding Fitness to
Practise cases. The School also reviewed methodology around finals, adopting a more
contemporary method of assessment to ensure students are better prepared to sit the final
exams. This has resulted in revised exam regulations for the finals exam and the panel saw
several documents illustrating this.
Other changes include a move from using case-based discussions to using Modified Objective
Structured Long Examination Records (MOSLER) as an assessment tool. There has also been
development with the ‘iDentity’ system in the monitoring of students. Pastoral support is
overseen by the School Progress and Support Committee, while decisions on disciplinary and
Fitness to Practise / Fitness to Study processes have recently been devolved to an
independent Professional Standards Review committee in order to ensure objectivity of
9

decision making and consistent ongoing pastoral support for students in difficulty. These
processes continue to evolve.
Finally, the panel were informed of the School’s Annual Monitoring and Review (AMR) and
Learning & Teaching Review (LTR) processes, also overseen by the BoS. The AMR is an
annual exercise to review the operation of the programme over the previous academic year
and to develop an action plan for the next year. The LTR takes place for all taught programmes
on a six-yearly cycle which is linked with the AMR process. The LTR is led by internal and
external peers and a student representative. It is tasked with reviewing and reporting on the
security of standards and the quality of learning. Both reports are considered by the BoS and
an action plan drawn up if there are any areas identified for improvement.
The team considered that there is a robust and complex quality assurance framework in
operation at University, Faculty and School level. This is underpinned by detailed processes
and a clear committee structure to monitor the quality of the programme and implement
changes. Documents provided to the panel clearly illustrated that the School manages any
issues relating to the quality of the programme efficiently and that programme changes are
adopted following the correct processes.
The associates also considered that there is a strong and established leadership team and
management structure within the School. The senior team have clearly defined responsibilities
and there is a collegiate sense of working together.
Requirement 10: Any concerns identified through the Quality Management framework,
including internal and external reports relating to quality, must be addressed as soon
as possible and the GDC notified of serious threats to students achieving the learning
outcomes. The provider will have systems in place to quality assure placements.
(Requirement Met)
Requirement 11: Programmes must be subject to rigorous internal and external quality
assurance procedures. External quality assurance should include the use of external
examiners, who should be familiar with the GDC learning outcomes and their context
and QAA guidelines should be followed where applicable. Patient and/or customer
feedback must be collected and used to inform programme development. (Requirement
Met)
Under this Requirement, the panel was tasked additionally with looking at how student
feedback is used to inform development of the programme.
The rigorous quality assurance framework within which the School operates has been
discussed in detail under Requirement 9. This illustrates the various internal processes and
committees that underpin the framework which operates at School, Faculty and University
level. The School consulted externally when reviewing their sign-up process to finals exams.
They confirmed that they adhere to the guidelines of the QAA Quality Code for Higher
Education which includes the QAA’s Framework for Higher Education Qualifications.
A vital aspect of external quality assurance of the programme is the use of external examiners
(EE). The team was impressed with the number of EEs being used. Various documents
outlining their function, responsibilities and training such as the External Examiner Policy and
External Examiner Handbook were available to the panel. There is a formal recruitment and
induction process and EEs are appointed centrally for four years initially. Nominated
appointees are initially recommended to the Board of Studies by the Chair of the relevant
Exam Board. The University’s central Learning & Teaching Development Service then
oversees the appointment criteria after receiving the School’s nomination. When appointed,
10

EEs receive a wealth of web-based resources to access plus the University’s Quality and
Standards Handbook with evidence seen of engagement.
EEs undertake a variety of functions. They are required to report on the quality and academic
standards of the University’s awards. They report on whether the School’s assessment
methods measure student achievement rigorously and fairly and are conducted in line with
relevant policies and regulations. They consider whether the standard of the programme meets
the standards specified in external guidance documents. This includes the QAA Quality Code
and the GDC’s learning outcomes. They are expected to highlight areas of exemplary practice
and innovation. They can also make recommendations for consideration by the Board of
Examiners and subsequently the BoS. Concerning examinations, the EEs are invited to
comment on draft exam papers, moderate exams and observe clinical exams. The EEs submit
a report after each round of the exams. The School confirmed that EEs are not directly
involved in examining students, consistent with the QAA Code of Practice. Reports from EEs
are provided to the BoS who consider any recommendations made by them in accordance with
the quality assurance framework for programme changes. The school cited the final
examination changes as an example. EEs are also invited to attend Board of Examiner
meetings.
The School has various methods for collecting patient feedback. These include a ‘Just One
Thing’ card that can be completed at clinics after each treatment episode. Feedback from
these cards is recorded in students’ portfolios as patient feedback. Questionnaires are
discussed between the student and the clinical supervisor at the time of completion. Further
patient feedback is gathered in specific circumstances. For example, at stage 4 in term 1,
students are asked to gather 10 detailed patient questionnaires on their interpersonal skills.
The School indicated that they have completed an educational research project to develop a
questionnaire specifically for collecting patient feedback. The panel suggests that the School
continue to develop this work on adopting a single method of collecting feedback and making
more effective use of patient feedback, not only as a method of informing student feedback,
but also as a tool to inform programme development. With the use of iDentity integral to the
course, it would make sense for patient feedback to be part of this system.
The panel considered how student feedback was being recorded and used to inform
programme development. It was explained to us that the SSC plays a part in the School’s
quality assurance framework, as discussed under Requirement 9. Student representatives
attend the BoS meetings. We noted students’ comments being recorded in Course Review
forms and students confirmed that programme changes were made as a result of their
feedback to the School. One example was when students suggested that earlier patient access
during the programme would be preferable. This was taken into consideration and resulted in a
new course entitled Introduction to Clinical Practice.
Requirement 12: The provider must have effective systems in place to quality assure
placements where students deliver treatment to ensure that patient care and student
assessment across all locations meets these Standards. The quality assurance systems
should include the regular collection of student and patient feedback relating to
placements. (Requirement Met)

11

Standard 3– Student assessment
Assessment must be reliable and valid. The choice of assessment method must be
appropriate to demonstrate achievement of the GDC learning outcomes. Assessors
must be fit to perform the assessment task.
Requirement 13: To award the qualification, providers must be assured that students
have demonstrated attainment across the full range of learning outcomes, and that they
are fit to practise at the level of a safe beginner. Evidence must be provided that
demonstrates this assurance, which should be supported by a coherent approach to the
principles of assessment referred to in these standards. (Requirement Met)
Under this Requirement, the panel was tasked additionally with looking at the sign-up process
for final examinations and access to a range and number of patients and whether these have
any impact on how this Requirement is met.
The panel reviewed the School’s Assessment Strategy which outlines how assessments and
examinations should be managed. This document indicates that students are encouraged not
to compartmentalise learning within the various taught courses and Stages but to adopt a
holistic approach to study. The School’s Guide to Assessment 2018 gives an overview of the
various assessment methods used, the grading system and criteria employed. The team
reviewed the Assessment Blueprint BDS 2015- 2019 spreadsheets which set out how various
assessments are blueprinted against the learning outcomes of the programme curriculum and
we considered this to be very comprehensive.
The School explained that they use a 4-point grading scheme and a grading matrix for all
examinations throughout the programme. In formative and summative clinical assessments the
grade of 3 is aligned to the standard of a safe beginner. Formerly, this was a system including
descriptors such as ‘unsatisfactory’. However, following dialogue with supervisors and students
it was considered these were too emotive and that a move to a numerical system was more
sensitive to students. The panel acknowledge the benefit in making such a change. We noted
that only grade levels 1, 3 and 4 are being used in INCCA’s and we questioned why 2 wasn’t
being used. We also noted the description of each grade and considered that these could be
more explicit, particularly grade 3 (the level of a safe beginner). The panel welcomed the
changes currently being made to the grade descriptors for Radiology.
The panel noted the wide range of assessment methods being used. In-course assessments
include essays, case reports and projects. For example, students undertake a Dental Public
Health project (based in outreach). Summative assessments include Multiple Choice
Questions, Modified Essay Questions, Short Answer Questions and Objective Structured
Practical Examinations (OSPE). Clinical assessments take the form of Case Discussions and a
variety of clinical exercises such as INCCAs, Objective Structured Clinical Examinations
(OSCE), MOSLERs and Structured Clinical Operative Tests (SCOT).
The School explained that there are 23 wide-ranging INCCAs covering core skills and
procedures in all clinical disciplines contributing to the Stage 5 final examination gateway.
Students must demonstrate competency at the level of a safe beginner in all INCCAs in order
to be eligible to sit finals. There is no compensation between the INCCAs. The School believes
students should have sufficient transferable skills if they pass these assessments and the
panel agreed with this rationale and commends this competency-based approach to
assessments. In addition, the majority of in-course assessments are marked by two individual
examiners.
The panel were given an explanation of the School’s sign-up process. All candidates must
successfully complete all the requirements of the Gateway before they are eligible to sit the
Stage 5 finals exam. These include both in-course knowledge and in-course clinical
assessments. There is no compensation between these two components. The sign-up process
12

involves a formal meeting whereby various School staff attend to review all the evidence
compiled against each student individually. Students’ personal circumstances can be taken
into account at this meeting. The meeting is attended by representatives from the School, the
Degree Programme Director, Stage 5 Examination Board Chair, Director of Student Progress
and the School Manager. Students explained that they were clear on the expectations of them
for sign-up, having received a lecture on the Gateway process which also covered
assessments, exams and the system of portfolio reviews.
At the inspection, the panel was presented with clinical data for year 5 students. The panel
considered there was disparity between the expected level of clinical activity set by the School
and the actual number of completed procedures achieved by students. From the data
presented, it was apparent that some students had not completed the number of procedures
specified by the School. For example, some skills hadn’t been clearly demonstrated and
students’ experience in paediatric dentistry appeared to be particularly variable. This led the
panel to have reservations as to whether all students were receiving a full breadth of
experience. When questioned, the School explained they were aspirational clinical targets
which students were encouraged to achieve in order to support and develop their skills and to
compliment the use of INCCAs. The data was not in itself a sole way of determining
competency and the School consider it preferable to look at the breadth and range of
experience of students and the transferability of skills acquired. Following this explanation, we
were reassured by the School that these aspirational targets complement the competencybased nature of the programme. We were assured that the data was not being used as a
means of informing student assessment. However, given that the data is entered by students,
we would encourage the School to develop a more rigorous auditing and monitoring system to
ensure that any issues with non-recording or inaccuracies can be dealt with.
The panel considered that the range of procedures for Paediatric patients did not cover certain
clinical procedures which were low when considering the clinical targets that were presented.
The School may wish to consider expanding the INCCA to ensure that students are assessed
in these areas, for example, preformed crowns, extractions, etc.
Requirement 14: The provider must have in place management systems to plan, monitor
and centrally record the assessment of students, including the monitoring of clinical
and/or technical experience, throughout the programme against each of the learning
outcomes. (Requirement Met)
Requirement 15: Students must have exposure to an appropriate breadth of
patients/procedures and should undertake each activity relating to patient care on
sufficient occasions to enable them to develop the skills and the level of competency to
achieve the relevant GDC learning outcomes. (Requirement Met)
Under this Requirement, the panel was tasked additionally with looking at access to a range
and number of patients and whether this has any impact on how this Requirement is met.
There are two outreach centres to the north and west of Newcastle and two to the east. The
locations represent a variety of patients and are all in high needs areas. All of the outreach
locations are subject to CQC inspection which provides a good level of quality assurance.
Students indicated that the outreach centres gave them good access to paediatric patients but
that some cancellations of these appointments had somewhat of an adverse effect on limiting
students’ access to these patients. However, overall students felt they saw a good range of
patients to gain the necessary clinical experience.
At the inspection, the School explained that patient recruitment can be challenging and are
making efforts to address this, particularly for paediatric patients. We recognise the efforts the
School are making to address this. The School explained that in order to ensure that students
13

have sufficient access to clinical cases, undergraduate patient waiting lists are structured to
facilitate the availability of cases suitable for developing core clinical skills. The School
indicated that they have processes in place to review and respond to any shortfall in waiting
lists and to actively recruit patients when waiting lists become low. This included specific clinics
to triage patients from the University web-based self-referral list. The panel had sight of this
impressive portal where the vast majority of patients are sourced. A small number are referred
from general dentists where appropriate and students are usually proactive in sourcing patients
for themselves and indicated that staff are supportive in helping them gain patient access and
give practical tips when patient numbers are low.
Students will treat the same patient until they qualify allowing continuity of care. The focus is
on delivering oral health in a longitudinal and continuous manner without any swapping of
patients where practical. The assumption is that patients will be treated for the full three clinical
years by the same student. Students indicated this continuity in the management of their
patient throughout this period was beneficial for their own development. The team agreed with
the School that it is important for patients not to be reallocated between students and that this
continuity of care to patients was good practice.
The monitoring of the range and number of clinical procedures undertaken by students is
carried out at Periodic Portfolio review meetings between students and clinical teachers. These
take place at four strategic times during clinical training. At these meetings, students’ clinical
experience is reviewed in each clinical area to check the appropriate breadth of patients and
procedures. These Portfolio reviews are informed by data recorded in ‘iDentity’, which records
productivity, quality of clinical care and any issues. Having had sight of this system, we saw
how student clinical activity is constantly monitored and reviewed. Supervisors can easily
review the breadth and depth of students’ clinical experience. In the event that students’
clinical experience was low, the School can easily put bespoke arrangements in place such as
strategically booking patients. Students’ progress towards the attainment of all GDC outcomes
is reviewed at Stage 4 by the Stage 5 Board of Examiners. This is done taking into
consideration of the learning outcomes that will be assessed in Stage 5. We had some
concerns that the input of data is student led. Although more onus should be placed on
students to ensure the data is accurate, the School might wish to consider a system of random
audit checks to monitor this.
Although the panel identified some variability between students regarding access to patients,
particularly paediatric patients, it was noted that by year 5 patient numbers between students
were more balanced.
Requirement 16: Providers must demonstrate that assessments are fit for purpose and
deliver results which are valid and reliable. The methods of assessment used must be
appropriate to the learning outcomes, in line with current and best practice and be
routinely monitored, quality assured and developed. (Requirement Met)
Requirement 17: Assessment must utilise feedback collected from a variety of sources,
which should include other members of the dental team, peers, patients and/or
customers. (Requirement Met)
Requirement 18: The provider must support students to improve their performance by
providing regular feedback and by encouraging students to reflect on their practice.
(Requirement Met)

14

Requirement 19: Examiners/assessors must have appropriate skills, experience and
training to undertake the task of assessment, including appropriate general or specialist
registration with a UK regulatory body. Examiners/ assessors should have received
training in equality and diversity relevant for their role. (Requirement Met)
Under this Requirement, the panel was tasked additionally with looking at staffing levels and
whether this has any impact on how this Requirement is met.
The School indicated that all internal examiners have a teaching qualification or some previous
experience of examining. Examiners involved in the assessment of clinical skills require
full registration with the GDC.
Chairs of Examination Boards attend specific training on this role and it is delivered by the
University's central Organisational Development Unit.
The team heard that new examiners are required to shadow experienced examiners. Prior to
the inspection, documentation provided by the School confirmed this, for example, in finals,
new examiners usually also receive training during mock exams in January.
At the inspection, the panel heard about the use of regular lunchtime and evening training
sessions in the form of various workshops which also included staff from outreach placements.
Subjects covered in these sessions included skills development, difficult interactions and
student support.
The School indicated that during OSCEs, all examiners are required to undertake a preexamination briefing which includes the opportunity to seek clarification on marking schemes. It
also allows role players to co-ordinate their scripts to ensure as much consistency between
OSCE stations as possible. We had sight of the OSCE Examiner and role-player briefing note
which confirmed this.
When new assessments and marking schemes are introduced, teams have the opportunity to
mark them which allows for training and examiner alignment. The School also hosts an annual
Educational Development Day in November where further training and alignment exercises are
held.
Staff from outreach confirmed to us they received clinical inductions to the local community
and induction with the School with whom they felt there were strong links. They indicated they
also have full access to the virtual Blackboard learning environment which encourages
inclusion in the team and consistent teaching on all sites.
The panel were given details of training provisions for equality, diversity and inclusion (EDI). At
a general level, the University ensures compliance with the Equality Act 2010 in respect of
employment procedures and student teaching, supported by central guidance. It is also
referred to in the BDS and BSc Professional Conduct Guide and Agreement. Regarding
training, all new staff undertake EDI training at induction and then every three years
afterwards. EDI training is monitored centrally though the University’s personal development
review process as well as the Trust’s Appraisal systems. Academic staff undertake EDI training
through an on-line training portal in the University’s central Learning Management System.
NHS staff involved in teaching and assessment for the School undertake EDI training through
their NHS electronic staff records (ESR). Prior to the inspection, the team saw PDR Forms for
Clinical Academic staff, a Safety Training Matrix, Induction Checklist and Mandatory Training
Checklist for Trust Grade Dentists confirming this. An EDI training record from May 2019
confirmed almost all staff had undertaken this training. Finally, we heard that EDI is frequently
covered as a standing agenda item on all Student-Staff Committees.
15

Requirement 20: Providers must ask external examiners to report on the extent to which
assessment processes are rigorous, set at the correct standard, ensure equity of
treatment for students and have been fairly conducted. The responsibilities of the
external examiners must be clearly documented. (Requirement Met)
Requirement 21: Assessment must be fair and undertaken against clear criteria. The
standard expected of students in each area to be assessed must be clear and students
and staff involved in assessment must be aware of this standard. An appropriate
standard setting process must be employed for summative assessments. (Requirement
Met)

16

Summary of Action
Req.
number

Action

Observations & response from
Provider

Due date

Observations from the provider on content of report
We would like to thank the GDC inspection team for their report which recognises
Newcastle University School of Dental Sciences robust management structure, and team
approach to delivering the BDS programme. In addition, it is gratifying to note that the
team were able to appreciate our success at not only developing our staff, but also
providing excellent pastoral care and support for our student colleagues.
We are delighted that our innovative and progressive approach to assessment was
recognised by the team, and that it was clear to the inspection team that students are
supported in their progression to safe beginners at graduation, having gained a broad
range of experience in a number of clinical settings (including outreach).
The panel suggest that the School continue to develop our work on collecting patient
feedback by adopting a single method of collecting feedback and making more effective
use of patient feedback. Having undertaken two robust and published educational
research projects to develop targeted patient feedback on individual student and on the
programme, we feel that trying to now combine these would potentially be counterproductive and lack a robust evidence base. Nonetheless we will continue to monitor
patient feedback on the programme (specifically the reporting of outcomes through Board
of Studies) and seek to modify process where indicated. Whilst patient feedback on
individual students is currently recorded on iDentity we will explore the feasibility of
increased use of technology to allow direct patient input.
The panel have encouraged the School to develop more rigorous auditing/monitoring of
iDentity data input by students, and we plan to explore how this can be best achieved in
order to deal with non-recording or inaccuracies in a timely fashion. The panel also
suggested an expansion of the number of INCCA that are required to be undertaken.
Following discussion of this suggestion the School will undertake a wholesale review of
the learning outcomes assessed within the current range of INCCAs in order to ensure
that assessment and transferability of clinical skills within and across different patient subpopulation’s remains appropriate.
Finally, we would like to thank the panel for commending the open dialogue with external
partners such as Health Education England working across the North East and Cumbria.
We would hope to continue to utilise that dialogue to externally validate ongoing
programme developments.

17

Recommendations to the GDC
Education associates’
recommendation
Date of next regular monitoring
exercise

The BDS qualification continues to be sufficient
for holders to apply for registration as a dentist
with the General Dental Council.
Annual Monitoring review 2020/2021

18

Annex 1
Inspection purpose and process

1. As part of its duty to protect patients and promote high standards within the professions it
regulates, the General Dental Council (GDC) quality assures the education and training of
student dentists and dental care professionals (DCPs) at institutions whose qualifications
enable the holder to apply for registration with the GDC. It also quality assures new
qualifications where it is intended that the qualification will lead to registration. The aim of
this quality assurance activity is to ensure that institutions produce a new registrant who has
demonstrated, on graduation, that they have met the learning outcomes required for
registration with the GDC. This ensures that students who obtain a qualification leading to
registration are fit to practise at the level of a safe beginner.
2. Inspections are a key element of the GDC’s quality assurance activity. They enable a
recommendation to be made to the Council of the GDC regarding the ‘sufficiency’ of the
programme for registration as a dentist and ‘approval’ of the programme for registration as a
dental care professional. The GDC’s powers are derived under Part II, Section 9 of the
Dentists Act 1984 (as amended).
3. The GDC document ‘Standards for Education’ 2nd edition1 is the framework used to
evaluate qualifications. There are 21 Requirements in three distinct Standards, against
which each qualification is assessed.
4. The education provider is requested to undertake a self-evaluation of the programme
against the individual Requirements under the Standards for Education. This involves stating
whether each Requirement is ‘met’, ‘partly met’ or ‘not met’ and to provide evidence in
support of their evaluation. The inspection panel examines this evidence, may request
further documentary evidence and gathers further evidence from discussions with staff and
students. The panel will reach a decision on each Requirement, using the following
descriptors:
A Requirement is met if:
“There is sufficient appropriate evidence derived from the inspection process. This evidence
provides the inspectors with broad confidence that the provider demonstrates the
Requirement. Information gathered through meetings with staff and students is supportive of
documentary evidence and the evidence is robust, consistent and not contradictory. There
may be minor deficiencies in the evidence supplied but these are likely to be
inconsequential.”
A Requirement is partly met if:
“Evidence derived from the inspection process is either incomplete or lacks detail and, as
such, fails to convince the inspection panel that the provider fully demonstrates the
Requirement. Information gathered through meetings with staff and students may not fully
support the evidence submitted or there may be contradictory information in the evidence
provided. There is, however, some evidence of compliance and it is likely that either (a) the
appropriate evidence can be supplied in a short time frame, or, (b) any deficiencies identified
can be addressed and evidenced in the annual monitoring process.”
A Requirement is not met if:

19

“The provider cannot provide evidence to demonstrate a Requirement or the evidence
provided is not convincing. The information gathered at the inspection through meetings with
staff and students does not support the evidence provided or the evidence is inconsistent
and/or incompatible with other findings. The deficiencies identified are such as to give rise to
serious concern and will require an immediate action plan from the provider. The
consequences of not meeting a Requirement in terms of the overall sufficiency of a
programme will depend upon the compliance of the provider across the range of
Requirements and the possible implications for public protection”
5. Inspection reports highlight areas of strength and draw attention to areas requiring
improvement and development, including actions that are required to be undertaken by the
provider. Where an action is needed for a Requirement to be met, the term ‘must’ is used to
describe the obligation on the provider to undertake this action. For these actions the
inspectors may stipulate a specific timescale by which the action must be completed or when
an update on progress must be provided. In their observations on the content of the report,
the provider should confirm the anticipated date by which these actions will be completed.
Where an action would improve how a Requirement is met, the term ‘should’ is used and for
these actions there will be no due date stipulated. Providers will be asked to report on the
progress in addressing the required actions through the annual monitoring process. Serious
concerns about a lack of progress may result in further inspections or other quality
assurance activity.
6. The QA team aims to send an initial draft of the inspection report to the provider within two
months of the conclusion of the inspection. The provider of the qualification has the
opportunity to provide factual corrections on the draft report. Following the production of the
final report the provider is asked to submit observations on, or objections to, the report and
the actions listed. Where the inspection panel have recommended that the programme is
sufficient for registration, the Council of the GDC have delegated responsibility to the GDC
Registrar to consider the recommendations of the panel. Should an inspection panel not be
able to recommend ‘sufficiency’ or ‘approval’, the report and observations would be
presented to the Council of the GDC for consideration.
7. The final version of the report and the provider’s observations are published on the GDC
website.

20

