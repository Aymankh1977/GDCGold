RE-INSPECTION REPORT
Education Provider /
Awarding Body:

The University of Manchester

Programme / Award /
Qualification:

Bachelor in Dental Surgery (BDS)

Outcome of 2012/13 report:

Recommended that the Manchester University
BDS programme remains sufficient for
registration. A re-inspection in the 2013/14
academic year is required to consider the newer
elements of the programme.

Remit and Purpose:

Full re-inspection referencing the Standards for
Education to determine continuing sufficiency of
the award for the purpose of registration with the
GDC as a dentist.

Learning Outcomes:

The First Five Years (Dentist)

Programme Inspection Dates:

7 April 2014 (Student sign-up meeting)
29-30 April 2014

Examination Inspection
Dates:

5-6 June 2014

Inspection Panel:

Susan Morison (Lay member and Chair)
Kim Piper (Dentist)
Shazad Malik (Dentist)
James Newton (Dentist)

GDC Staff:

Luke Melia (Lead)
Laura Harrison

Outcome of 2013/14 reinspection report:

Recommended that the Manchester University
BDS programme remains sufficient for
registration as a dentist with the GDC.

1

Re-inspection summary
The GDC inspected the BDS programme at the University of Manchester during the 2012/13
academic year. The inspection panel recommended that the qualification was sufficient for
holders to apply for registration as a dentist with the GDC, but also recommended that a full
re-inspection was to be undertaken in 2013/14. The decision was made on the basis that
further evaluation was required of some of the newer aspects of delivery. The inspectors
also wished to have the opportunity to assess the School’s progress in addressing the
actions contained in the 2012/13 report.
The inspectors’ recommendation for a re-inspection was accepted by the GDC Registrar
and completed in April 2014, with the inspection panel returning to the final examinations in
June. The inspectors were impressed with the manner in which the School had responded
to the 2012/13 GDC inspection report. The senior management had not only acknowledged
the areas that were highlighted for improvement, but started an ambitious and well-targeted
action plan. The reaction of staff at all levels was one of insight and innovation and should
be commended.
A total of 13 Requirements have been revised from either Not Met or Partly Met to now
being considered Met or Partly Met with clear plans for future compliance. One Requirement
(21) was revised from a Met to a Partly Met. The School had made a significant change in
no longer using external examiners to assess students. Instead, teams of internal examiners
were utilised and external examiners took on the role of overall quality assurance. The
inspectors felt that although this was a positive step forward, further training and experience
was necessary for the internal teams to ensure a standardized approach. In addition, the
inspectors considered that the School needed to ensure examiner pairs were allocated to
examine in areas of dentistry most appropriate to their background and expertise.
The inspection panel was very encouraged to find the whole philosophy to the quality
assurance of outreach placements had changed over the last 12 months. It was evident that
outreach staff were more confident in their relationship with the School, with communication
massively improved. An Outreach Lead had been appointed and started to work with the
Clinical Directors from the four Trusts where the Outreach Placements were situated. This
had fed into meetings of an Outreach Teachers Group, which had developed a formal policy
that will include an agenda for annual visitations and calibration of grading. Outreach staff
had also been included in School training away days.
The inspectors were pleased to see that the School had a made a positive start to the review
of its assessment strategy. There was evidence that the School was reflecting on what might
be the best range of assessments to suit the overall competency based structure of the
programme. A lead in Assessment/Examinations had been appointed and an
Assessment/Examinations Group was created to take on the overall responsibility for the
area. With input from Year Leads and other senior staff, the group have been considering
grading schemes, combination of grades and student achievement of their clinical
competencies.
As a priority, the inspection panel felt that Assessment/Examinations Group needed to
ensure that a clear progression pathway for students achieving their core clinical
competencies was developed. It was necessary for the inspectors to request paper records
to cross reference the data held in the CEDAR and LIFTUPP systems, which did not always
accurately reflect the full attainment of a student’s clinical activity. More comprehensive
assessment blueprinting was also required and should be undertaken in conjunction with the
programme being mapped to the learning outcomes published in Preparing for Practice.
The inspectors were aware that a number of the new initiatives being implemented by the
School will need time to become fully embedded in the programme. In some areas,
2

particularly in relation to the assessment structure, the inspection panel felt unable to fully
revise their original Requirement decisions from a Partly Met because a lot of the work
remained in progress. The inspectors were optimistic that, were they to review the work
completed by the School committees after a full year in operation, sufficient data would be
seen to indicate the Requirements were being Met or significantly closer to becoming Met.
These areas will be considered through the GDC annual monitoring process.
The inspection panel wished to thank the staff, students, and external stakeholders involved
with the BDS programme for their co-operation and assistance with the re-inspection.

Inspection process and purpose of Inspection
1.

As part of its duty to protect patients and promote high standards within the professions
it regulates, the General Dental Council (GDC) quality assures the education and
training of student dentists and dental care professionals (DCPs) at institutions whose
qualifications enable the holder to apply for registration with the GDC and new
qualifications where it is intended that the qualification will lead to registration.

2.

The aim of this quality assurance activity is to ensure that these institutions produce a
new registrant who has demonstrated, on graduation, that he or she has met the
outcomes required for registration with the GDC. This is to ensure that students who
obtain a qualification leading to registration are fit to practise at the level of a safe
beginner.

3.

The inspection focuses on four Standards, with a total of 29 underlying Requirements.
These are contained in the document Standards for Education.

4.

The purpose of this inspection was to make a recommendation to the Council of the
GDC regarding the ‘sufficiency’ of the programme for registration as a dentist in the UK.
The GDC’s powers are derived under Part II, Section 9 of the Dentists Act 1984 (as
amended) to determine sufficiency of the programme.

5.

Inspection reports may highlight areas of strength and draw attention to areas requiring
improvement and development, including actions that are required to be undertaken by
the provider. Where an action is needed for a Requirement to be met, the term ‘must’ is
used to describe the obligation on the provider to undertake this action. For these
actions the inspectors may stipulate a specific timescale by which the action must be
completed or when an update on progress must be provided. In their observations on
the content of the report, the provider should confirm the anticipated date by which
these actions will be completed. Where an action would improve how a Requirement is
met, the term ‘should’ is used and for these actions there will be no due date stipulated.
Providers will be asked to report on the progress in addressing the required actions
through the annual monitoring process. Serious concerns about a lack of progress may
result in further inspections or other quality assurance activity.

6.

The provider of the qualification has had the opportunity to provide factual corrections
on the draft report. Following the production of the final report the provider was asked to
submit observations on, or objections to, the report and the actions listed. Where the
inspection panel had recommended that the programme is sufficient for registration, the
Council of the GDC have delegated responsibility to the GDC Registrar to consider the
recommendations of the panel. Should an inspection panel not be able to recommend
sufficiency, the report and observations would be presented to the Council of the GDC
for consideration.

3

The Inspection
7.

This report sets out the findings of a re-inspection of the Bachelor of Dental Surgery
(BDS) awarded by Manchester University. The GDC publication Standards for
Education (version 1.0 November 2012) was used as a framework for the inspection.
This re-inspection forms part of a series of BDS inspections being undertaken by the
GDC in 2012-2014.

8.

The re-inspection was comprised of two visits. The first, referred to as the programme
inspection, was carried out on 29 and 30 April 2014. This involved a series of meetings
with programme staff involved in the management, delivery and assessment of the
programme and a selection of BDS students. The second visit took place between 5 and
6 June 2014 and is referred to as the student sign-off inspection and was undertaken at
the final examinations. In addition, one inspector and the lead QA Officer attended the
student sign-up meeting for final examinations on 7 April 2014.

9.

The report contains the findings of the inspection panel across the two visits together
with consideration of supporting documentation prepared by the School to evidence how
the individual Requirements under the Standards for Education have been met. The
main focus of the re-inspection was in regards to Requirements that were deemed
Partly Met or Not met, in the 2012/13 inspection report (published on the GDC website).
However, the inspectors were also permitted to revise their consideration of any of the
29 Requirements under the Standards for Education.

Overview of Qualification
10. The BDS programme sits within the Faculty of Medical and Human Sciences within the
University of Manchester. The programme has an annual intake of around 80 students.
The duration of the programme is 188 weeks over five years of study and training. The
programme is designed to deliver the learning outcomes contained in the GDC
document The First Five Years (3rd edition, 2008).
11. The BDS programme delivery has been designed around the three key principles of
enquiry-based learning (EBL), integration of learning and team working. Students attain
compulsory core components with clinical elements delivered in a variety of primary and
secondary care settings including Manchester Dental Hospital and eleven Outreach
Centres across Greater Manchester.
12. For the 2012/13 academic year, the School implemented the Longitudinal Integrative
Foundation Training Undergraduate Postgraduate Pathway (LIFTUPP) system
throughout the programme. LIFTUPP is a newly developed central recording IT
programme that has established workplace-based assessment strategies which run on
iPads with data captured and stored on a centrally held database. The aim for the
system, once fully operational, is to continuously and longitudinally monitor learner
development with easily accessible academic and clinical performance data for both
students and tutors. LIFTUPP is designed to map learning outcomes to assessment and
delivery, in addition to providing a means by which to centrally record and calibrate the
assessment of students’ longitudinal clinical activity. LIFTUPP thus supports the delivery
of the BDS programme as a central mapping, monitoring and recording system. It is
anticipated that LIFTUPP will also provide students with a portfolio of clinical activity that
they can take forward into foundation training.

4

Evaluation of Qualification against the Standards for Education
13. The provider was requested to update their self-evaluation of the programme against
the individual Requirements under the Standards for Education. This involved stating
whether each Requirement is met, partly met or not met and to provide evidence in
support of their evaluation. The inspection panel examined this evidence, requested
further documentary evidence and gathered further evidence from discussions with staff
and students.
14. The inspection panel once again used the following descriptors to reach a decision on
the extent to which the BDS of Manchester University meets each the Requirements:
A Requirement is met if:
“There is sufficient appropriate evidence derived from the inspection process. This
evidence provides the inspectors with broad confidence that the provider demonstrates the
Requirement. Information gathered through meetings with staff and students is supportive
of documentary evidence and the evidence is robust, consistent and not contradictory.
There may be minor deficiencies in the evidence supplied but these are likely to be
inconsequential.”
A Requirement is partly met if:
“Evidence derived from the inspection process is either incomplete or lacks detail and, as
such, fails to convince the inspection panel that the provider fully demonstrates the
Requirement. Information gathered through meetings with staff and students may not fully
support the evidence submitted or there may be contradictory information in the evidence
provided. There is, however, some evidence of compliance and it is likely that either (a) the
appropriate evidence can be supplied in a short time frame, or, (b) any deficiencies
identified can be addressed and evidenced in the annual monitoring process.”
A Requirement is not met if:
“The provider cannot provide evidence to demonstrate a requirement or the evidence
provided is not convincing. The information gathered at the inspection through meetings
with staff and students does not support the evidence provided or the evidence is
inconsistent and/or incompatible with other findings. The deficiencies identified are such as
to give rise to serious concern and will require an immediate action plan from the provider.
The consequences of not meeting a Requirement in terms of the overall sufficiency of a
programme will depend upon the compliance of the provider across the range of
Requirements and the possible implications for public protection.”

5

Standard 1 – Protecting patients
Providers must be aware of their duty to protect the public. Providers must ensure that
patient safety is paramount and care of patients is of an appropriate standard. Any risk
to the safety of patients and their care by students must be minimised
Requirements
Met
Partly Not
met
met

1. Students will provide patient care only when they have
demonstrated adequate knowledge and skills. For clinical
procedures, the student should be assessed as competent in
the relevant skills at the levels required in the pre-clinical
environments prior to treating patients *



2. Patients must be made aware that they are being treated by
students and give consent *



3. Students will only provide patient care in an environment
which is safe and appropriate. The provider must comply with
relevant legislation and requirements regarding patient care *



4. When providing patient care and services, students are to be
supervised appropriately according to the activity and the
student’s stage of development



5. Supervisors must be appropriately qualified and trained.
Clinical supervisors must have appropriate general or
specialist registration with a regulatory body



6. Students and those involved in the delivery of education and
training must be encouraged to raise concerns if they identify
any risks to patient safety *



7. Should a patient safety issue arise, appropriate action must be
taken by the provider *



8. Providers must have a student fitness to practise policy and
apply as required. The content and significance of the student
fitness to practise procedures must be conveyed to students
and aligned to GDC student fitness to practise guidance. Staff
involved in the delivery of the programme should be familiar
with the GDC Student Fitness to Practise Guidance
* = Requirement has been revised from the 2012/13 report

6



GDC Comments
Requirement 1: Students will provide patient care only when they have demonstrated
adequate knowledge and skills. For clinical procedures, the student should be
assessed as competent in the relevant skills at the levels required in the pre-clinical
environments prior to treating patients (Requirement remains Met)
The inspection panel was satisfied that the good practices outlined in their 2012/13 inspection
report were continuing. The School operates a highly detailed and well planned framework for
ensuring students have been assessed as competent in the relevant skills before being
allowed to treat patients. Students are aware that they have a professional responsibility not to
perform any clinical work on a patient until they have passed the relevant clinical skills
assessment.
The inspectors felt that senior tutors were suitably mindful that there could be a significant
period between a student learning skills in a pre-clinical environment and their first opportunity
to practise the procedure on a patient in clinic. As a further safeguard, the inspectors thought
that skills tests could be given a formal expiry date. This would allow tutors to monitor a time
period after which students will require a refresher programmes to ensure they have
maintained an appropriate level of competency to be permitted to treat patients.
Requirement 2: Patients must be made aware that they are being treated by students
and give consent (Requirement revised from Partly Met to Met)
In the 2012/13 inspection report, the School explained that students were identified on clinics
by their blue tunics (a different colour to other staff members), and also wore badges which
provided their name and indicated that they are part of ‘The School of Dentistry’. The
inspection panel felt that it was not entirely clear how patients were made aware of the
significance of the colour of the tunic that their practitioner was wearing, either in the hospital
or in outreach. No posters were seen that explained the different coloured uniforms and the
School accepted that notices in outreach were not consistently displayed.
Two actions were recorded in regards to this requirement in the 2012/13 inspection report.
i. The School must highlight the significance of the blue tunics that students wear in the clinical
environment so patients can clearly distinguish them from other members of the dental team.
Staff seniority in relation to each colour of uniform should be clearly advertised.
ii. A patient information document to the same standard as the NHS Foundation Trust form
entitled “Information for Patients Accepted for Restorative Treatment from Undergraduate
Student Dentists” must be extended to all clinical facilities where students work.
In response to action i. the School has produced posters, which show students and staff in
their different coloured tunics together with a clear indication for what the specific colours
mean. The posters are displayed in all areas where students see patients.
In response to action ii. the Dental Hospital form entitled “Information For Patients Accepted for
Restorative Treatment from Undergraduate Students Dentists” has been modified. A separate
one to cover children treated by students has been produced. These have been circulated
through all clinical areas in the Trust. A “New Patient Information” leaflet has also been
designed. It is sent out by the Trust with a patient’s first appointment. The posters and
information for patients were presented and approved by a new Outreach Teachers’ Group in
advance of their roll out.

7

Students in all years showed an excellent understanding of the importance of consent and the
importance of clear communication with patients. Formal guidance is published and included in
their inductions at the beginning of each year. The year three, four, and five students displayed
a more progressive appreciation of the principles of informed consent having spent time
working on clinics.
Requirement 3: Students will only provide patient care in an environment which is safe
and appropriate. The provider must comply with relevant legislation and requirements
regarding patient care (Requirement revised from Partly Met to Met)
The inspection panel was satisfied that the clinical environment was safe, and relevant
legislation was met throughout the Dental Hospital, School and within outreach placements.
The School has improved the communication with the Dental hospital and are implementing an
excellent plan for the quality assurance of outreach placements (detailed in full at Requirement
10). The plan will include a regular round of visits to all placements, the findings of which will
be compiled into an Outreach Placement Report for consideration at the Undergraduate
Programme Committee (UPC). The inspectors’ understanding was that reports by such bodies
as the Care Quality Commission (CQC) and other formal monitoring of the safety and propriety
of the clinical environments will be managed through this reporting mechanism.
The inspection panel was encouraged to hear staff from the School and Hospital talk about the
shared responsibilities for maintaining a safe environment. It was a theme repeated in several
areas of discussion over the course of the inspection. Individuals were eager to explain
measures such as a Clinical Effectiveness Committee with University representation and
clinical dash boards that offer easy access to a wealth of NHS data that is being captured
locally.
The School also highlighted that Health Education England North West continually updates the
Learning and Development Agreement, which includes ensuring all clinical work is undertaken
in a safe of environment. Any impact on the provision of dentistry is jointly considered by the
University of Manchester, University of Liverpool and University of Central Lancashire.
Requirement 4: When providing patient care and services, students are to be
supervised appropriately according to the activity and the student’s stage of
development (Requirement remains Met)
The inspection panel remain satisfied that the supervision levels within the programme are
appropriate. The ratio of staff to students continues to be one staff member to eight clinically
active students. The students confirmed that they were content with the level of supervision
and staff showed an understanding of the importance of appropriately matching supervision to
a student’s stage in development.
Requirement 5: Supervisors must be appropriately qualified and trained. Clinical
supervisors must have appropriate general or specialist registration with a regulatory
body (Requirement remains Met)
The inspection panel once again considered the qualifications and registration of the staff
members to be appropriate for working in the capacity as supervisors on the programme.
In the 2012/13 report, the School acknowledged that there needed to be further recruitment in
some areas, particular within senior restorative roles. The School provided an update on their
recruitment plans, which were very positive. Positions that have been signed-off at either an
advertising or shortlisting stage include a Researcher in Basic Science, Senior Lecturer and
Consultant in Restorative Dentistry with a special interest in Periodontology, a Clinical
Academic in Paediatrics, a Health Service Researcher (Biostatistics and Methodology), and a
8

Consultant in Special Care Dentistry.
The inspection panel felt the appointments will strength the programme and provide further
depth to the clinical and teaching teams.
Requirement 6: Students and those involved in the delivery of education and training
must be encouraged to raise concerns if they identify any risks to patient safety
(Requirement revised from Partly Met to Met)
In the 2012/13 inspection report, the inspection panel were advised of several reporting
mechanism for patient safety incidents. However, it was difficult for the inspectors to see how
the School actively encouraged staff and students to make use of the system.
One action was recorded in regards to this requirement in the 2012/13 inspection report:
The School must introduce a clear policy for how students and those involved in the delivery of
education and training can formally raise concerns relating to patient safety. The document
should show the pathway for dealing with such issues and indicate at what stage University
protocols are to be engaged.
The inspection panel was shown a new policy in regards to raising concerns within the School.
The document has formally set down the appropriate pathways to follow once a concern is
raised. There are clear mechanisms and points of contact for the students to bring any issues of
concern to the School’s attention and an indication for when School and University protocols are
to be engaged. The guidance has been developed with input from all relevant parties (School,
NHS, and outreach) and shows a strong insight into the need for a culture of candour following
the publication of the Francis Report in 2013.
The inspection panel was encouraged by the attitude of the staff and students when the
importance of raising concerns was discussed. There was a sound awareness of the
professional obligation to raise concerns with the students sharing the ethos and being
considered a member of a professional team with the same responsibilities as senior staff
members.
The School has recently introduced a ‘Dental School Charter’ which was developed in
conjunction with the Faculty and the NHS Trust in 2012. The agreement has been updated
to cite the key themes of the newer GDC publication Standards for the Dental Team.
Students are expected to sign and return a slip that confirms they have read and understood
the charter’s content. It is annually renewed at the beginning of each year of study.
Requirement 7: Should a patient safety issue arise, appropriate action must be taken by
the provider (Requirement revised from Partly Met to Met)
It was noted in the 2012/13 inspection report that the inspection panel was confident that
patient safety issues would be escalated and appropriately handled. Their judgement was
based on the professionalism displayed by staff and senior management and their appreciation
of the vital importance of all patient safety issues being correctly dealt with as a matter of
priority. However, the inspectors were concerned that the management systems the School
were operating could not be relied on to identify the full range of potential risks to patient
safety.
On re-inspection, the inspectors were pleased to see that the management system in the
School of Dentistry has been revisited. A review has been undertaken of the remit, membership
and roles of the committees and the reporting lines have been made more efficient with defined
responsibilities spread amongst the various groups. The role of the Director of Undergraduate
9

Education has been revised so other team members are included in the dissemination of
information (these changes are detailed in full at Requirement 9).
The inspection panel are now satisfied that the School is operating a management structure
that will identify the full range of potential risks to patient safety. The improved reporting lines
will help ensure appropriate actions are taken should a patient issue arise. The revised
committee framework will also allow for a clear audit of process and decision points.
Requirement 8: Providers must have a student fitness to practise policy and apply as
required. The content and significance of the student fitness to practise procedures
must be conveyed to students and aligned to GDC student fitness to practise guidance.
Staff involved in the delivery of the programme should be familiar with the GDC Student
Fitness to Practise Guidance (Requirement remains Met)
The inspection saw evidence that the School has a student fitness to practise policy that is
aligned to GDC guidance and staff were familiar with the guidance.
As of the 2012/13 academic year, a professional traffic light system has been used by the
School for staff to report incidents relating to student professionalism. The cards (red, amber
and green) can be issued by any member of hospital staff and are also active within outreach. A
guidance poster was published to act as an aide memoire for the application of the system. The
poster was placed in all clinical areas and distributed to placements.
It was noted in the 2012/13 inspection report that students felt there were some inconsistencies
with how staff had been applying the criteria for issuing professionalism cards.
One action was recorded in regards to this requirement in the 2012/13 inspection report:
The School should ensure that the issuing of professional traffic light cards are reviewed
regularly to ensure consistency of approach when staff are awarding the cards. Calibration
should be included within formal staff training events.
The inspection panel was encouraged to find that further training and calibration material has
been produced in regards to how staff should apply the criteria for the Professionalism Traffic
Light System. An online training package has been produced and is now available following a
pilot period. The training includes cases which can be used a calibration tool for when the
issuing of a professionalism card is appropriate.
The Dental Hospital held an Annual Clinical Effectiveness (ACE) day in January 2014. The
online training for the professionalism cards was presented at the day and staff had the
opportunity to go through the cases and discuss them live. Attendees included Hospital and
University staff, dentists, nurses, reception and records staff. Outreach teaching staff have also
been given access to the online training with the chance to go through the cases and discuss
them live at a half day away day organised by the Dental School in April 2014.
The inspection panel appreciate that some decisions will never be popular with students and
remain mindful that the system is still a fairly new initiative. They echo their opinion from the
last inspection report that the system is an excellent addition to the programme and offers a
framework for professionalism to be monitored in all clinical environments. The inspectors were
encouraged to note that staff fully understood how important it was that the system is operated
consistently. As discussed, this was a topic covered at a staff away day and a Year Lead is
reviewing students’ views as part of their PhD study. The inspectors want to see the School’s
commitment to training and calibration continue, as this will be the only way to ensure the
cards remain a fair and reliable tool.

10

Actions
Req.
Actions for the provider
Number
1
All tutors must be mindful of the periods of time between a
student learning skills in a pre-clinical environment, and the first
opportunity for them to practise the procedure on a patient in
clinic. The School should introduce formal expiry dates to the
achievement of skills tests by students. There should be a clear
policy on revocation and reinstatement following any further
assessment.
8

The School should continue its commitment to staff training and
calibration for the issuing of professionalism cards to ensure the
system remains fair and reliable.

11

Due Date
(if applicable)
GDC Annual
Monitoring 2015

GDC Annual
Monitoring 2015

Standard 2 – Quality evaluation and review of the programme
The provider must have in place effective policy and procedures for the monitoring and
review of the programme
Requirements
Met Partly Not
met
met
9. The provider will have a framework in place that details how it
manages the quality of the programme which includes
making appropriate changes to ensure the curriculum
continues to map across to the latest GDC outcomes and
adapts to changing legislation and external guidance. There
must be a clear statement about where responsibility lies for
this function
10. The provider will have systems in place to quality assure
placements *





11. Any problems identified through the operation of the quality
management framework must be addressed as soon as
possible
12. Should quality evaluation of the programme identify any
serious threats to the students achieving learning outcomes
through the programme, the GDC must be notified at the
earliest possible opportunity *





13. Programmes must be subject to rigorous internal and external
quality assurance procedures *



14. External examiners must be utilised and must be familiar with
the learning outcomes and their context. Providers should
follow QAA guidelines on external examining where
applicable *



15. Providers must consider and, where appropriate, act upon
concerns raised or formal reports on the quality of education
and assessment *



* = Requirement has been revised from the 2012/13 report
GDC comments
Requirement 9: The provider will have a framework in place that details how it manages
the quality of the programme which includes making appropriate changes to ensure the
curriculum continues to map across to the latest GDC outcomes and adapts to
changing legislation and external guidance. There must be a clear statement about
where responsibility lies for this function (Requirement remains Partly Met)
The pre-inspection documentation states that the Undergraduate Programme Committee
(UPC) continues to be the framework t hat the School uses to manage programme and
curriculum changes.
In the 2012/13 inspection report, the inspection panel was unable to see how curriculum
changes were proposed, considered and ultimately authorised through the UPC. Review for
12

new initiatives appeared informal with the recorded discussion centring on more day to day
logistics of the School’s operations rather than a strategic quality assurance of the
programme. It was acknowledged by the senior staff at the time that the UPC minutes had not
been clear enough in representing and monitoring curriculum changes and more needed to
be done to reflect where decisions had been made.
A committee organogram was considered during the 2012 programme inspection that showed
the Undergraduate Programme Committee (UPC) had a number of subcommittees operating
beneath it. There included a Dental Progress Committee, a Staff/Student Liaison Committee,
an Outreach Liaison Committee and a Vocational Training Liaison Committee.
The inspection panel noted that organogram structure appeared a sound framework for the
School management. However, the inspectors could not find sufficient evidence of the
discussions from each of the various committees being fed into the UPC. The material
reviewed suggested that the UPC actually had management of the remits defined in some of
the names of the sub-committees, with the sub-structure operating in a somewhat isolated and
limited capacity.
Three actions were recorded in regards to this requirement in the 2012/13 inspection report:
i. The School must provide a clear statement about where the function of strategic quality
assurance of the programme lies within the management framework. Decision making within
this area must be clearly audited and demonstrate what topics were covered at which
committee and how new initiatives received authorisation to be implemented. Interactions
between the School, the University Faculty and the Hospital should be evident within the
process.
ii. The School must improve the clarity of its recording of discussions within the management
structure and its various committees. Each committee must have a distinct remit with a schedule
for frequency of meetings and appropriate underpinning policy or regulations. How information
is fed into a central administrative framework and disseminated to staff and students must be
clearly defined.
iii. The School must provide further management support to the Director of Undergraduate
Education and review the remit within the role. Consideration must be given to where delegation
of responsibilities might be appropriate as well as contingency planning for circumstances
where the Director may become unavailable.
In response to the actions, the School has revisited their management system and committee
structure. A review has been undertaken of the remit, membership and roles of the committees
and the reporting lines have been made more efficient with defined responsibilities spread
amongst the various groups.
The UPC meets monthly during the academic year and retains responsibility for the curricula,
teaching and assessment of undergraduate students. The senior management team explained
that some of the other committees have been renamed and some new ones created though
the model remains similar to the Organogram considered in 2012.
A Health and Conduct committee has replaced the Progress Committee which has taken on
the role of monitoring student progress as directed by the provision of the University’s
Academic Regulations. The group assesses students referred to it from the sign-up to final
examinations, who may require remedial action plans or have mitigating circumstances to be
considered.
The Staff/Student Undergraduate Liaison Committee has been reconstituted. Previously, there
13

was student representation on the UPC. The Staff/Student Liaison Committee now meets
monthly on its own accord to consider matters of undergraduate education including delivery of
curriculum and student experience. The minutes are then considered at the following UPC
meeting.
The Outreach Liaison Committee has now become the Outreach Teachers’ Group. It is chaired
by an Outreach Lead, which is a newly created role for the oversight of outreach placements,
and meets once a semester. The forum will consider the delivery of teaching, learning and
assessment outside of the Dental School and Hospital. Health and safety, training of Outreach
Teachers and monitoring of student’s clinical activity is also included in the terms of reference.
The Vocational Training Liaison Committee has been renamed the Foundation Training Liaison
Committee. It is chaired by the Regional Programme Director of Dental Foundation Training
North West Deanery and meets on a biannual basis.
An Assessment/Examination Group has been created and started to meet in December 2013.
The forum has been set up to consider the appropriateness and structure of assessments, plan
for their execution and review and quality assure their suitability. It has also taken on
responsibility for the consideration and responses to External Examiner reports. The group is
scheduled to meet on a monthly basis.
A Clinical Development Review Panel has been created and will meet each semester. The
group is chaired by the Director of Undergraduate Education and considers clinical
development of undergraduate students using LIFTUPP. It will review Professionalism traffic
light cards, student absences, and the attainment of clinical competencies.
The inspectors were pleased to note evidence that the UPC is now considering the findings of
the subcommittees working beneath it rather than attempting to manage the vast majority of
the undergraduate programme in a single forum. There was an acceptance amongst the staff
that the UPC had become weighed down by its previous functions, and the ability to focus on
specific elements of the course in smaller, dedicated groups has proven hugely beneficial. The
UPC has been freed up to become more strategic in its discussions and decisions.
As part of the process of review, the School has looked at its minutes of meetings. The
inspectors were told that there has been a concerted effort to ensure that actions and
decisions are followed through and suitably audited. Evidence was seen that improvements
have been made in this area with discussions recorded in the most appropriate committee
and then fed into the UPC for ultimate consideration.
In the 2012/13 inspection report, the inspectors highlighted the wide ranging scope within
the role of the Director of Undergraduate Education. This role has been revised with other
members of the team taking on some of the responsibilities for the position. This has helped
with the dissemination of information throughout the School as more people are involved
and empowered with decision making. There was also evidence of a management team
operating together at a senior level, which mitigates the risk of one key person becoming
unavailable without suitable cover.
The inspection panel were able to identify more formal interaction between the Dental
School and the Dental Hospital, but the relationship with University Faculty remained
somewhat unclear. As outlined in the 2012/13 inspection report, the School has a significant
degree of autonomy for making changes to course design without having to interact with the
wider University. There was also limited evidence for when or how overarching quality
assurance reviews of the School were undertaken by the University and how the system
was aligned with School processes and fed into the current management. (This area will be
considered in more detail at Requirement 13).
14

The inspectors were disappointed to note that the School has not yet mapped their curriculum
against the latest GDC learning outcomes published in Preparing for Practice in September
2011. With some recent changes in senior management, there was a degree of uncertainty for
when the transfer from the old learning outcomes detailed in The First Five Years will take
place. There appeared to have been some work completed on the project, but worked on in
isolation, outside of the relevant committees.
With the mapping unchanged, there remained some difficulty for the inspection panel to
understand exactly how the mapping of the learning outcomes always worked in practice. The
School are urged to start their mapping to Preparing for Practice immediately and ensure there
is a coherent transition plan in place. The inspectors are encouraged by the work being done
by the Assessment/Examination Group and would expect the School to utilise this forum when
completing the new mapping. The inspectors look forward to reviewing this piece of work
through the GDC annual monitoring exercise.
The inspection panel felt that the function of the revised committee structure was showing
promising signs and, in time, will provide a robust structure to manage the programme and
curriculum. However, the inspectors agreed that they were unable to fully revise their
original decision that the requirement is partly met because the committee structure has not
been in place long enough for a complete review of its running. Not enough evidence was
available during the inspection period but it is thought that there will be within the next
academic year. The inspectors are therefore optimistic that were they to review committee
minutes after a full year in operation, sufficient data would be seen to warrant the
requirement being deemed met. This is something that will be reviewed through the GDC
annual monitoring process.
Requirement 10: The provider will have systems in place to quality assure placements
(Requirement revised from Partly Met to Met)
It was detailed in the 2012/13 inspection report that the range of outreach placements
operated by the School was commendable but the inspection panel was disappointed that
there was no formal, centralised system of quality assurance. The evidence indicated a
passive approach to interacting with outreach and coordinating placements, which required
significant improvement. The School acknowledged at the time that the monitoring of
placements should be more pro--‐active and further development was needed in this area.
Four actions were recorded in regards to the requirement in the 2012/13 inspection report:
i. The School must indicate how it proposes to quality assure the delivery of education for
students in outreach placements. This should include a defined policy and formal links to ensure
a safe environment at each location with regular opportunities for information to be shared with
the School. A designated coordinator for outreach placements is highly recommended.
ii. The School must devise formal inductions for outreach placements that are standard
procedure at the beginning of a student’s time at each location. This must offer the outreach
staff an opportunity to gauge clinical skill levels and review the competencies that the student
has met and those still to be attained. Such information must be readily accessible at the
outreach site.
iii. The School must provide a clear policy on the use of clinical activity data gained from
outreach placements. If the policy states that these data may influence decisions regarding a
student’s competency to sit a final examination, the quality assurance of the assessment of
students must be sufficiently robust and a relevant policy relating to the quality assurance of
assessment in outreach placements must be produced.
15

iv. The School must provide training for all clinical staff within outreach in the School’s
assessment practices. It must ensure that there are regular opportunities for calibration of the
awarding of grades between other outreach sites and the School itself.
In response to the actions, a former Head of School has taken on the role of Outreach Lead,
tasked with co-ordinating and quality assuring outreach placements. The School currently has
eleven outreach placements operating over four NHS Trusts: Manchester Community Dental
Service, Salford Community Dental Service, Pennine Care NHS Foundation Trust, and
Bridgewater Community Health Care NHS Trust.
A first meeting was held with the four Clinical Directors of Outreach Placements in December
2013. A meeting was also convened with the outreach teachers separately. Though the
meetings were initially informal, notes were taken and available for consideration by the
inspectors. More formal evidence of the School’s progression was subsequently seen in the
workings of the Outreach Teachers Group, where formal minutes are kept and presented to the
UPC.
The minutes of the Outreach Teachers Group show that the Outreach Lead has been working
closely with all relevant staff to produce a workable quality assurance framework that will be
effective across the various sites and NHS Trusts. A formal policy has been set down in draft.
This includes an agenda for annual visitations, the first round of which was completed between
March and May 2014. The results of the visits will form the basis of an Outreach Placement
Report to be annually submitted to the UPC. Other criteria for the inclusion in the report will be
Facilities, Infection Control, Health and Safety, Medical Emergencies and Patient and Student
Experience.
There had been some concern during the 2012/13 inspection that students were not given
formal inductions when they arrived at new placements. The evidence suggested that
procedures varied from site to site and outreach staff had taken it upon themselves to make
initial reviews of a student logbook to establish the clinical level the student could operate at.
The inspectors were encouraged to find that LIFTUPP data is now supported with a
Centralised Electronic Dental Academic Record (CEDAR). LIFTTUP provides details of clinical
skill levels from clinics at the Hospital and other outreach sites, while CEDAR records student
achievement of competencies. Outreach teachers have full access to both systems, which
feeds into a centralised monitoring system. All supervisors are able to see students’
progression and are aware of everyone’s input into the database. They can review records of
tutor meetings that are written into the system, which will highlight any clinical skill
weaknesses, or emerging patterns of behaviour for School intervention. The aim is for a formal
induction to be introduced at the start of each outreach placements, which will include dialogue
between student, Year Lead and outreach teachers. In addition, formal feedback mechanisms
for staff students and patients are being piloted.
Outreach staff attended the training day in April 2014 and will be invited to future training
events. This will ensure that everyone will know how to access relevant information and are
updated on a regular basis.
The grading of students will be a frequently reviewed and calibrated though the Outreach
Teachers Group and staff training sessions. The inspectors were satisfied that this area has
improved with the LIFTUPP grading scale more embedded in the programme. However,
further work is required to provide a clear approach to the use of clinical activity data gained
from outreach placements in relation to progression. There should be clear evidence of the
clinical activity undertaken by a student prior to the ‘sign-off’ of a competency. This aspect of
the student attainment will be further discussed at Requirements 16 and 19.
16

The inspectors were very encouraged to find the whole philosophy to the quality assurance of
outreach placements has changed over the last 12 months. Outreach staff were more
confident in their relationship with the School, with communication massively improved in what
is now a three way process between the School, the Trust, and the staff working in the clinical
sites. This regular communication provides an excellent basis for the quality assurance of
clinical placements. Its collaboration has already been seen in the development of raising
concerns policy.
Requirement 11: Any problems identified through the operation of the quality
management framework must be addressed as soon as possible (Requirement remains
Partly Met)
The inspection panel remain satisfied that problems identified through the quality management
framework would be addressed. Senior management and staff have consistently showed a
sound understanding of the importance of identifying risk and acting accordingly to prevent
issues from escalating.
As outlined in Requirement 9, the quality management framework has improved with the
UPC now working more strategically, considering the findings of the subcommittees working
beneath it (as depicted in the organogram in the School of Dentistry Management document).
As with Requirement 9, the inspection panel felt unable to fully revise their original decision
that the requirement is partly met because the committee structure has not been in place
long enough for a complete review of its running. Not enough evidence was available during
the inspection period but it is thought that there soon will be. The inspectors are therefore
optimistic that were they to review committee minutes after a full year in operation, sufficient
data would be seen to warrant the requirement being deemed met. This is something that
will be reviewed through the GDC annual monitoring process.
Requirement 12: Should quality evaluation of the programme identify any serious
threats to the students achieving learning outcomes through the programme, the GDC
must be notified at the earliest possible opportunity (Requirement revised from Partly
Met to Met)
The inspection panel remain confident that should any serious threats to the students
achieving learning outcomes be identified, the GDC would be notified at the earliest
opportunity. The School have adopted a more team minded approach in their management
structure with all senior figures displaying a strong awareness that serious threats to any
aspect of the programme would require contact with the regulator.
Requirement 13: Programmes must be subject to rigorous internal and external quality
assurance procedures (Requirement remains Partly Met)
The inspection panel reviewed evidence that showed a significant amount of improvement has
been made with regards to internal and external quality assurance, but there are still some
areas that require further improvement.
External examiners are now employed to review specific aspects of the School’s examinations
and sign-up process. Since the 2012/13 inspection report, there has been a change in the role
of the external examiner. The external examiner no longer participates in the assessment of
the student but instead functions as a quality assurance observer and reviews all aspects of
the examinations. Details of the deployment of external examiners will follow in Requirements
14 with further aspects explored in Requirements 15 and 22.
17

The changes made to the School’s internal management framework have been detailed in
Requirements 9 and 11. As noted at Requirement 9, the inspection panel was able to identify
more interaction between the Dental School and the Dental Hospital within the new committee
structure, but the relationship between the School and University Faculty remained somewhat
unclear.
Apart from the annual monitoring reports and quinquennial periodic reviews, there appeared
limited evidence of the Schools formal interaction with University quality assurance
mechanisms. The last periodic review undertaken by the Faculty of Medical and Human
Sciences was in 2009. The School was due to have its next Faculty Periodic Review in April
2014, but this was cancelled to focus on addressing the actions in the 2012/13 GDC report.
The Periodic Review will now be undertaken in the 2014/15 academic year.
The inspectors heard that within the University, there is a Faculty Committee and a Teaching
Committee. The Year Five Lead currently chairs the latter. However, there were few details for
the exact nature of the information provided to Faculty, or what information and decisions were
then returned to the School. Further scrutiny of committee minutes suggested that the
information being shared took the form of brief updates that were not recorded in any
purposeful way.
It was also seen that under the previous programme management structure, a wide ranging
annual monitoring report could be compiled within the School but only receive input from a
very limited number of senior authors or author. The document did not seem to be shared
within any of the committees operating at the time, with the accuracy of the review suffering
from its creation in such isolation. Once submitted to the Faculty, the reports seemed to simply
be logged for reference with the exact purpose of the exercise not defined with any clarity.
The inspectors reviewed some of the policies that are produced by the University Faculty but
not adopted by the School. The School is afforded special dispensation due to the nature of
the subject and its regulatory requirements. While it is appreciated that a BDS has certain
inherent aspects that requires exemption from some of the rules that govern other subjects, a
number of the policies appeared to offer an excellent foundation, which could be adopted by
the School. For example, the University assessment framework appeared clear and wellstructured and may be something for the Assessment/Examination Group to consider in future.
With the School’s significant degree of independence, the inspectors felt they were unable to
say the programme has been subject to what can be described as rigorous external quality
assurance. The gap between the School and the University Faculty remains too wide. There
are some benefits to a certain level of autonomy for the School to manage its own operations,
particularly in regards to changes to the curriculum. However, without University Faculty
overview, there is a lack of overall quality assurance, which would strengthen the programme
and provide a valuable external perspective.
Requirement 14: External examiners must be utilised and must be familiar with the
learning outcomes and their context. Providers should follow Quality Assurance
Agency (QAA) guidelines on external examining where applicable (Requirement revised
from Partly Met to Met)
The inspection panel was satisfied that those undertaking the external examiner role were
appropriately qualified and familiar with the learning outcomes. External examiners are
included in monitoring the progress routes through Year 1 to Year 4, and an external examiner
scrutinised the student sign-up meeting for final examinations.
The School no longer uses external examiners in the undertaking of assessments, which has
brought their practice more in line with the latest understanding of QAA guidance. External
18

examiners have been given a new remit for overall quality assurance with access to all aspects
of the examinations. The inspectors were told by the External Examiners that all
documentation was provided in advance and the School were happy to field all queries and
take feedback.
Requirement 15: Providers must consider and, where appropriate, act upon concerns
raised or formal reports on the quality of education and assessment (Requirement
revised from Not Met to a Met)
In the 2012/13 inspection report, the inspection panel was not satisfied that formal reports were
considered appropriately by the School. Evidence was reviewed that indicated a passive
approach to external examiner reports. The UPC minutes provided showed very little
discussion on external examiner reports. The panel were provided with 11 sets of UPC
minutes, none of which indicated that external examiner reports were discussed in any detail
and there was no evidence provided that they were considered elsewhere.
One action was recorded in regards to this requirement in the 2012/13 inspection report:
The School must improve its system of reviewing external examiner reports. There must be an
identifiable forum that is responsible for interaction with the external examiners and
consideration of their reports. A defined process is necessary for authorising amendments
based on the advice, and rationale should be recorded for when guidance is not taken forward
for changes.
The inspection panel was pleased to note that the new Assessment/Examination Group has
taken on responsibility for the consideration and response of External Examiner reports. The
Group is chaired by an Assessment/Examinations Lead who now manages assessment
design, progression of students, standard setting, auditing, and quality assurance. Early
indications are that Assessment/Examination Group is functioning well and has provided a
suitable forum for the review of all external examiner feedback, whether submitted in a written
report or provided in person during Examination Boards or other assessment meetings.
The inspectors would urge more attention to detail is paid to external examiner reports. One of
the written papers for final examinations had been standard-set too high. The high pass
threshold had been commented on by an external examiner prior to the examination but these
comments were not acted upon by the School. In addition, an unseen clinical scenario had to
be changed after the GDC inspection panel highlighted it had already been used in a written
paper. Again, this oversight had already been reported to the School by an external examiner
and was not followed up. These oversights will be considered in more detail at Requirements
22 and 23.

Actions
Req.
Number
9

Actions for the provider

Due Date
(if applicable)

(i)

The School must continue to establish its revised
management framework and provide relevant committee
minutes in their response to the GDC annual monitoring
exercise next year

GDC Annual
Monitoring
2015

(ii)

The School must make the mapping of the programme to GDC Annual
the learning outcomes in the GDC document Preparing
Monitoring
for Practice a matter of priority.
2015
19

10

The School should include minutes from the Outreach Teachers
Group and details of staff training sessions involving Outreach
staff, in their response to the GDC annual monitoring exercise
next year

GDC Annual
Monitoring
2015

13
(i)

The School must include details of the Periodic Review
scheduled to be completed in the 2014/15 academic year
in their response to the GDC annual monitoring exercise
next year

GDC Annual
Monitoring
2015

(ii)

The School must provide evidence for where
consideration has been made in having closer ties with
the University Faculty. This should be included in the
response to the GDC annual monitoring exercise next
year

GDC Annual
Monitoring
2015

The School should include minutes from the
Assessment/Examination Group in their response to the GDC
annual monitoring exercise next year

GDC Annual
Monitoring
2015

15

20

Standard 3– Student assessment
Assessment must be reliable and valid. The choice of assessment method must be
appropriate to demonstrate achievement of the GDC learning outcomes. Assessors
must be fit to perform the assessment task
Requirements
Met Partly Not
met
met
16. To award the qualification, providers must be assured that
students have demonstrated attainment across the full range
of learning outcomes, at a level sufficient to indicate they are
safe to begin practice. This assurance should be underpinned
by a coherent approach to aggregation and triangulation, as
well as the principles of assessment referred to in these
standards



17. The provider will have in place management systems to plan,
monitor and record the assessment of students throughout
the programme against each of the learning outcomes



18. Assessment must involve a range of methods appropriate to
the learning outcomes and these should be in line with
current practice and routinely monitored, quality assured and
developed



19. Students will have exposure to an appropriate breadth of
patients/procedures and will undertake each activity relating
to patient care on sufficient occasions to enable them to
develop the skills and the level of competency to achieve the
relevant GDC learning outcomes





20. The provider should seek to improve student performance by
encouraging reflection and by providing feedback1
21. Examiners/assessors must have appropriate skills,
experience and training to undertake the task of assessment,
appropriate general or specialist registration with a regulatory
body *
22. Providers must ask external examiners to report on the extent
to which assessment processes are rigorous, set at the
correct standard, ensure equity of treatment for students and
have been fairly conducted





23. Assessment must be fair and undertaken against clear
criteria. Standard setting must be employed for summative
assessments *



24. Where appropriate, patient/peer/customer feedback
should contribute to the assessment process *



1

Reflective practice should not be part of the assessment process in a way that risks effective student
use

21

25. Where possible, multiple samples of performance must
be taken to ensure the validity and reliability of the
assessment conclusion
26. The standard expected of students in each area to be
assessed must be clear and students and staff involved
in assessment must be aware of this standard *





* = Requirement has been revised from the 2012/13 report
GDC comments
Requirement 16: To award the qualification, providers must be assured that
students have demonstrated attainment across the full range of learning outcomes,
at a level sufficient to indicate they are safe to begin practice. This assurance
should be underpinned by a coherent approach to aggregation and triangulation, as
well as the principles of assessment referred to in these standards (Requirement
remains Partly Met)
The inspection panel agreed that there had been some significant improvements in the
School’s assessment strategy. In the 2012/13 inspection report, it was noted that the
inspectors required several aspects of the School’s assessment strategy to be clarified
and did not always receive satisfactory explanations to their further enquiries. Throughout
the inspection process, there was insufficient evidence to enable the inspectors to fully
determine how students’ skill acquisition had been recorded and evaluated before the
introduction of LIFTUPP. It was also not possible to adequately determine how various
assessment components and grading criteria operated in making a final decision on a
student’s clinical ability.
Seven actions were recorded in regards to the requirement in the 2012/13 inspection report:
i. The School must review its assessment structure to ensure a clear progression pathway can
be audited. There must be an overall strategy for how each component of the programme fits
together to produce final assessment decisions, particularly on a student’s clinical ability.
Assessment decision points must be openly and robustly evidenced.
ii. The School must review the clinical competencies. Consideration must be given to the
system’s appropriateness as a hurdle to progression when competencies are currently being
carried forward by students from Year 3 to Year 5.
iii. The School must improve the monitoring and recording of students achieving clinical
competencies. There must be a clearly defined policy for when and how students are assessed
in these skills, which must be developed with an accurate central management system to track
student progress.
iv. The School must review the role of the Academic Advisor. Consideration must be given to
whether the system has the appropriate robustness and policy to function as a tool for student
monitoring and to influence progression decisions, including sign-up to final examinations. The
use of non-dental School staff in this role must also be examined.
v. The School must clarify how continuous clinical performance contributes to overall student
attainment across the programme and its consideration at student sign-up. A distinction must
be evident between assessment of clinical performance and the achievement of clinical
competencies with any interrelation between the two components clearly defined in School
policy.
22

vi. The School must ensure that a clear audit of evidence is maintained throughout the process
for student sign-up to final examinations. The evaluation of students that are signed up with
conditions still to be met or are to be considered by a Dental Progress Committee should be
precisely tracked through each subsequent stage of appraisal with a final decision point clearly
evidenced. The system needs to be transparent and display exactly what evidence has been
used to underpin decision making on student ability and attainment.
vii. The School must ensure that every component of student assessment is monitored and
that the results are centrally recorded.
In response to the actions, the School has reviewed its assessment structure and
introduced the Assessment/Exam Group that has been described in Requirements 9 and
15. There have been some encouraging developments in the clarity of the assessment
strategy and progress pathways.
One member of the inspection panel and the lead Quality Assurance Officer from the GDC
attended the student sign-up meeting on 7 April. The meeting was once again identified by
the School to be where the aggregation of decision-making was performed with further
triangulation to be conducted at the Examination Board.
The criteria for sign-up to final examinations for Year 5 candidates has been revised and
was recorded as:










Attendance
Academic Advisor meeting
SDR meetings
Professionalism Cards
Competences
Clinical Performance
Coursework
Integrated Patient Care cases
Trust Core E-learning

Attendance
Satisfactory student attendance was again recorded as missing fewer than 10 sessions or
having mitigating circumstances accepted for a higher number of absences that was not
deemed critical to a satisfactory level of achievement. Students with 10 or more absences
were now considered at the newly established Health and Conduct Committee (previously the
Progress Committee).
A student with 5-9 absences received a warning letter outlining the consequences should they
reach 10 or more. A student with less than 5 absences is deemed to have fulfilled this
requirement for sign-up.
The inspection panel felt this was an appropriate standard and procedure. Student attendance
appeared to be logged in the CEDAR and LIFTUPP systems with a central review overseen by
an Administration Manager.
Academic Advisor meeting
In the 2012/13 inspection report, the inspection panel was not satisfied with the adequacy of
the Academic Advisor system and are pleased to see it underwent an immediate review.
23

Academic Advisors have now become a purely pastoral function and no longer play any part in
the monitoring of student progress. They do not review or consider clinical logbooks, or assist
students in obtaining treatments that they may be requiring for competencies. This has
removed the risk of a student being advantaged by having an advisor within the Dental School
over a student who has a non-dental member of staff fulfilling the role.
There is an Academic Advisor Meeting Proforma in CEDAR for meetings to be recorded.
Academic Advisor meetings are noted at the sign-up meeting for information purposes only.
Should it be found that a meeting has not occurred, a letter will be generated to remind a
student to arrange one, however this is no longer critical for sign-up.
SDR meetings
The School have introduced Student Development Review meetings, which are recorded on
CEDAR. They are conducted by the Year Lead as a running check on student progression
throughout the year. Academic Advisors were previously responsible for this appraisal and the
inspection panel are pleased to see the Year Leads have taken over. A Year Lead is a far
more appropriate person to fulfil the role.
The inspectors appreciate that the SDR meetings are a new initiative and hope that the School
can see the potential for further development. Currently, there is no formal policy stating how
many SDR meetings are required with the number of meetings recorded for information only at
the sign-up meeting.
Professionalism Cards
Professionalism cards were considered at the sign-up meeting in 2013 though not formally
cited within the sign-up criteria. In the 2014 meeting, professionalism cards have been
recorded as a requirement for sign-up. Students who have received Red Cards are discussed
with the potential for referral to the Health and Conduct Committee for more serious issues or
multiple offensives.
Competences
The inspection panel found that the student achievement of core clinical competences was far
more in line with its stated function as a hurdle for yearly progression. However, there
remained a lack of clarity within the overall system and its central recording.
The School explained that competences are now recorded in the CEDAR system, which is
monitored by the Year Leads in SDR meetings, and the Undergraduate Administration office.
The underlined data for all student clinical activity is held in LIFTUPP and forms the base for
continuous assessment.
At the sign-up meeting in April 2014, there was evidence to show that the competencies were
now largely being attained within the relevant year. The small number of students who were
carrying over outstanding procedures to another year, had clear deadlines for when noncompletion would be a matter for escalation and/or a failure of a hurdle to progression. For
sign-up to final examinations, Year 5 students had to have achieved a satisfactory
performance in all of the core clinical competences, including Year 3 and 4 competencies.
The inspection panel felt that the School still needed to do more to show the progression
pathway of students achieving the core clinical competencies. It was necessary for the
inspectors to request paper records to cross reference the data held in the CEDAR and
LIFTUPP systems, which did not always accurately reflect the full attainment of a student’s
24

clinical activity. Students that had been signed-off as having achieved their competencies, did
not have the corresponding evidence against their clinical performance recorded in LIFTUPP.
After scrutiny of the paper records, the inspectors were satisfied that any gaps found in student
attainment were subsequently down to some of the students’ clinical work not being recorded
in the databases.
Core clinical competencies will be considered further at Requirement 19.
Clinical Performance
Student clinical performance was monitored in LIFTUPP, a system now in its second year in
operation. The system flagged students as either green (developing at expected level), amber
(development needed in areas specified), or red (requiring the student to see Year Lead). For
sign-up to final examinations, Year 5 students must have achieved satisfactory overall
performance with any candidate highlighted in red within the system, discussed at the meeting
on 7 April.
The inspectors were able to see how LIFTUPP is developing and were impressed with the
amount of information that is recorded in the database. The specific details of the treatments
being performed by a student are excellent. For example, the exact tooth and quadrant being
worked on can be seen along with the materials used for any procedure.
It was indicated in the 2012/13 GDC inspection report that there needed to be more of a
distinction between assessment of clinical performance and the achievement of clinical
competencies with any formal interrelation between the two components clearly defined in
School policy. This has not been developed yet and the interrelationship between the two
remains unclear. The School needs to formalise this area to show the clear accumulation of a
student’s clinical skills.
Student clinical performance will be considered further at Requirement 19.
Coursework
Students complete a clinical audit in Year 5 and a number of case scenarios. The progression
is monitored by a coursework tutor and was considered a workable approach.
Integrated Patient Care cases
The Integrated Patient Care cases for case presentations in the final examinations were once
again well monitored. Any aspect of treatment that was still to be done in time for the
examinations in June had been planned and appointments scheduled with patients.
Trust Core E-learning
A new element of sign-up for final examination is the Trust Core E-learning modules.
These are split into four categories:





Annual Corporate Mandatory Training modules
CORE Clinical Mandatory Training modules
Stand Alone Training modules for Dental Hospital.
Ad-hoc Stand Alone Clinical Mandatory Training modules

25

Final examinations
As they did at the 2013 inspection, the inspection panel tracked the students identified with
caveats to their sign-up for final examinations. They reviewed the minutes from the Health and
Conduct Committee and considered evidence of student attainment. The minutes and
paperwork demonstrated that the Health and Conduct Committee had reviewed each of the
students highlighted with deficiencies and considered suitable evidence for their progression
decisions.
The inspectors went on to scrutinise student clinical activity. The inspection panel accepts that
the CEDAR and LIFTUPP systems will grow to provide detailed monitoring of student clinical
activity. As outlined under Competences and Clinical Performance, there currently remains a
lack of detail in the evidence that is used to underpin the assessment of student clinical ability.
Without a formal policy for the achievement of core clinical competencies or a full record for the
continuous assessment that has led up to achievement of a competency, the true amount of a
student’s clinical exposure and the evidence of their skill are not entirely evident. The GDC
does not set a minimum target of numbers for clinical procedures, and appreciates that raw
numbers are not necessarily an indication of competence. However, without accurate
recording of the level achieved for each item of dentistry that a student has performed, the
inspectors had some difficulties in seeing how clinical tutors can get a full picture of student
skills.
The inspection panel was mindful that the degree award is a competency based programme
and the students have completed their clinical training in advance of the final examinations.
Without satisfactory achievement of the core clinical competencies, a student will not be signed
up to take part in presentation and unseen cases. The inspectors accept that this is a common
structure for final year dental students to complete their course of study, but felt the School
might seek to introduce some aspect of practical clinical dentistry to finals.
The current model for the final assessments is mainly a test of a student’s knowledge rather
than their practical skills. The unseen cases were focused on patient management and the
presentation case was an overall review of some work completed by students. The technical
skills were not assessed at the point of delivery. The Assessment/Examination Group are
encouraged to consider how the School’s framework might be developed to bring in a clinical
aspect to the final examinations.
Ultimately, the inspection panel was assured that the students had reached the level of being
fit to practise as a safe beginner and should be permitted to join the GDC register. There was a
better base of evidence for the School to show their rationale for assessment decisions, though
further clarity in this area is still needed.
The inspectors will review the progress in this area through the GDC annual monitoring
exercise.
Requirement 17: The provider will have in place management systems to plan, monitor
and record the assessment of students throughout the programme against each of the
learning outcomes (Requirement remains Partly Met)
The inspection panel was informed that the School remains confident in its overall programme
structure but, in light of the 2012/13 GDC inspection report, acknowledged the crucial need to
adopt better management systems for the recording of student assessment.
The learning outcomes remain developed in five themes that run vertically through the
programme. The themes are:
26







Human Health and Disease
The Mouth in Health and Disease
Clinical Competence and Patient management
Teamwork, ICT, Reflective Practice and Communication
Scientific Understanding and Thought

The School described the development of the five themes as providing vertical integration. The
framework has been designed to ensure continuous progression through the five years with
the student gaining knowledge, skills and attitudes that build on those gained in previous
years.
The inspection panel still had some reservations about the difficulty in identifying where
specific topics were formally taught. The EBL framework, by its nature, is one that lacks formal
structure and the School needs to be mindful that there should always be an audit of evidence
for each student’s attainment across the learning outcomes.
There were signs that the revised management system will, in time, enable the School to
appropriately track the practical progression of all of the students through each theme,
particularly in relation to clinical achievements. As they received more and more information,
the CEDAR and LIFTUPP systems will build a strong base of knowledge of student
achievement for the various committees to be able to make well evidenced progression
decisions. The inspectors felt that more comprehensive assessment blueprinting would add
significant robustness to applying this data to the achievement of learning outcomes.
Requirement 18: Assessment must involve a range of methods appropriate to the
learning outcomes and these should be in line with current practice and routinely
monitored, quality assured and developed (Requirement remains Partly Met)
In the 2012/13 GDC inspection report, the inspection panel noted that the School had
demonstrated a range of assessment methods within their mapping of the learning outcomes.
The inspection panel was satisfied that there was an assessment strategy that discriminated
against weak and strong students although the structure for how each component fitted
together was unclear, and some aspects could not be described as current practice.
Two actions were recorded in regards to the requirement in the 2012/13 inspection report:
i. The School must review its delivery of OSCEs and consider whether they could be structured
to be more focused on clinical skills testing.
ii. The School must improve the monitoring of assessments and their appropriateness. There
must be a clear strategy for assessment reviews, with a designated forum that has
responsibility for overall quality assurance of assessment design and implementation.
In response to the actions, the School has set up the Assessment/Examination Group, which
has already been detailed in Requirements 9 and 15. The group has taken on the responsibility
for the monitoring of assessments and their appropriateness and has made a strong start.
There was evidence that the Assessment/Examination Group have reviewed the content of the
OSCE stations for this year’s exam diet and made some modifications to make them more
clinically oriented. An online training package has been designed for all examiners to ensure
calibration. LIFTUPP has been used to manage a bank of Single Best Answer (SBA) questions
with several new questions set for use across each year of the programme. The questions
have been peer reviewed and standard set.

27

The inspection panel was confident that the Assessment/Examination Group will improve the
range of assessment methods and promote the use of best practice in the area. Once again,
the inspectors felt unable to fully revise their original decision that the requirement is partly met
because a lot of the work remains in progress. The inspectors are optimistic that were they to
review the work completed by the committee after a full year in operation, sufficient data would
be seen to warrant the requirement being deemed met. This is something that will be reviewed
through the GDC annual monitoring process.
Requirement 19: Students will have exposure to an appropriate breadth of
patients/procedures and will undertake each activity relating to patient care on
sufficient occasions to enable them to develop the skills and the level of competency to
achieve the relevant GDC learning outcomes (Requirement remains Partly Met)
The inspection panel considered the clinical competencies that students are expected to
achieve year on year in some depth.
There are 10 competencies for achievement in Year 2, 50 in Year 3, 24 in Year 4, and 3 in
Year 5. The range of skills that the students must obtain showed an appropriate depth and
range. However it remained difficult to audit how and when student competences were
achieved, and the exact detail of the breadth of patients and procedures being undertaken. In
addition, it continued to be unclear what capacity the student had been operating in on clinics;
whether the candidate had been observing, providing treatment under supervision, or
practising independently.
As outlined in Requirement 16, competences are recorded in the CEDAR system, which is
monitored by the Year Leads in SDR meetings, and the Undergraduate Administration office. It
remained that students have two attempts to pass a competency with a third attempt possibly
granted if mitigating circumstances are accepted by the Health and Conduct Committee.
Competencies can be achieved in outreach, and the understanding once again gathered by
the inspectors was that students opted to have a competency assessed when they felt ready.
The inspection panel reiterate that they are satisfied with the outlined framework for the
achievement of competencies, but continue to be concerned by a lack of clarity and formality
for the actual assessment used for the achievement of the core targets. There was no
guidance on how many times a student has to complete a procedure before they can indicate
they feel ready to be tested, or whether a first attempt may be the one and only time the
procedure is performed if deemed satisfactory. There also remained no detail for how the
actual tests are standardised each time, or how calibration between assessors was managed,
particularly in outreach.
It was seen that LIFTUPP records each stage of a clinical treatment, which is then counted
under a relevant title. The inspection panel could appreciate the benefits of counting the
individual stages of a treatment, particularly in regards to identifying transferable skills, but it
was felt that an overall record of completed work was also required. This would avoid any
possibility of the numbers being misleading, as initially, it was thought that students had a high
number of restorations and/or extractions to their name, though when the data was fully
explored, it was found that a number of stages of the same treatment had been recorded
separately, rather than a large number of completed restorations and/or extractions.
The inspectors wished to point out that stages of treatment should not necessarily span the
achievement of skills in separate areas of clinical work. For example, under Minor Oral Surgery
(MOS), a distinction should be made between a student doing an extraction and performing a
item of MOS. It would not be appropriate for the same treatment to be counted twice to fulfil
criteria in both areas of skill.
28

The inspectors were able to see a much fuller picture of the details that are produced by the
CEDAR and LIFTUPP systems. There is evidence to show that tutors and students are able to
see clinical attainment and feedback, which can allow teaching to be tailored to an individual’s
needs and weaknesses. Staff and students commented that the buy-in to LIFTUPP is time
consuming but manageable and the benefits have been considerable. The inspectors
appreciate that the recording systems are still fairly new and the databases need time to build.
Having had to request paper records to verify the findings in the systems, the inspectors urge
the School to ensure that the accuracy of the data being inputted into CEDAR and LIFTUPP is
closely monitored and reviewed. Accuracy of data will be paramount for supporting the
progression pathway of students achieving core clinical competencies.
The inspection panel was informed that part of the Assessment/Examination Group remit will
be to look at competencies and review what exactly core skills are. The School acknowledged
that there were a large amount of competencies for achievement in Year 3 and there could be
a more even spread across the years. The inspectors were strongly of the opinion that a more
equal distribution of competencies between the years would be beneficial and reduce the
potential for some being carried over from year to year.
The inspectors once again felt that the relationship between the monitoring and achievement of
clinical performance and the monitoring and achievement of clinical competencies should be
more defined. The interrelation between the two components should be developed into a real
strength with LIFTUPP showing the progression of a student as they build their skills into the
achievement of the competencies, which can then be noted in more of an overview on
CEDAR.
Requirement 20: The provider should seek to improve student performance by
encouraging reflection and by providing feedback2 (Requirement remains Partly Met)
The 2012/13 GDC inspection report highlighted that Academic Advisors had been employed as
the main reviewer of student portfolios. There was a “Summary of Progress” sheet used for
meetings, which recorded a rudimentary level of reflection and feedback. The inspectors noted
that student reflective practices appeared narrowly focused with the examples reviewed
suggesting a limited engagement in the practice, with small details recorded rather than any
serious reflections on clinical practice noted.
Two actions were recorded in regards to the requirement in the 2012/13 inspection report:
i. The School must continue to develop the engagement of students with reflection. There
should be more clarity about how self-reflection is evaluated and used to influence assessment
and/or progression decisions.
ii. LIFTUPP offers the potential for feedback to be well targeted and extensive. The School
should continue to explore maximising this element of the system.
As detailed in Requirement 16, Academic Advisors have now become a purely pastoral
function and no longer play any part in the monitoring of student progress. The School have
introduced Student Development Review meetings, which are recorded on CEDAR and
include elements of reflection and feedback recorded in the database.
The School informed the inspectors that they are currently reviewing all aspects of student
reflection. A member of staff has been given a lead role and will consider the best strategies
for encouraging student reflection. The inspectors’ understanding is that CEDAR and LIFTUPP
2

Reflective practice should not be part of the assessment process in a way that risks effective student
use

29

will play a key role in promoting reflection and providing targeted feedback.
It was demonstrated how LIFTUPP can summarise a student’s performance and provides
immediate feedback. The database can also display a feedback summary. Students once
again were of the opinion that LIFTUPP had improved the quality of feedback with more tutor
interaction, a view echoed in the inspectors’ discussions with clinical teaching staff.
The inspection panel look forward to considering further updates on the findings of the staff
member’s review, along with any subsequent new initiatives, via the GDC annual monitoring
process.
Requirement 21: Examiners/assessors must have appropriate skills, experience
and training to undertake the task of assessment, appropriate general or specialist
registration with a regulatory body (Requirement revised from Met to Partly Met)
As noted in Requirement 14, the School no longer uses external examiners in the
undertaking of assessments. Internal examiner pairings were used for the first time during
final examinations this year.
One action had been recorded in regards to the requirement in the 2012/13 inspection
report:
The School must provide a more comprehensive examiner briefing at the final
examinations. There must be a consistent approach adopted by all assessors to ensure
examinations are conducted fairly. Independent marking must be undertaken before
discussion is entered into among examining teams. Leading questions should not be
permitted at any stage of the clinical examinations. There should be no changes made to
the examination methodology once the first candidate has been assessed.
The School submitted details of the internal examiners, and all held the appropriate
registration with the GDC. A comprehensive examiner briefing was provided in advance of
the final examinations with clear guidelines and advice. Consistent examination conditions
were maintained throughout the case presentations and unseen cases, managed by a
dedicated team of dental nurses.
The inspectors did find evidence to suggest that some examiner pairing may not have
been the most appropriate with regards to experience and training in the specific areas of
dentistry being assessed. There were also examples of examiners not following the
guidance from the examiner briefing, with leading questions or prompts seen on a number
of occasions. It was thought that the practice might have occurred less had there been
marking descriptors for presentation cases, which would help standardise the questions
being asked. However, it was also seen in the unseen cases that there was an
inconsistent approach between the examiner pairs in relation to using the radiographs and
including questions around what was seen on the x-rays. Standardisation of examiner
practice is something that should be developed through the Assessment/Examination
Group.
The inspection panel appreciated that the change from using external examiners for
examining, to utilising a team wholly comprised of internal staff, is a significant one. The
inspectors were optimistic that as the internal team build their experience, errors will
reduce and the best combinations of people will become more apparent. This needs to be
supported with a regular and comprehensive training schedule linked to staff development
plans.

30

Requirement 22: Providers must ask external examiners to report on the extent to
which assessment processes are rigorous, set at the correct standard, ensure
equity of treatment for students and have been fairly conducted (Requirement
revised from a Partly Met to a Met)
The Inspection panel was very encouraged by the School’s revision of its remit for external
examiners.
Two actions had been recorded in regards to the requirement in the 2012/13 inspection report:
i. The School must employ external examiners to provide an overview of the complete
examination process. In accordance with QAA guidance, external examiners should not
directly participate in assessing students and should be given the freedom to review wider
aspects of the assessments.
ii. Written papers should be reviewed by more than one external examiner.
As reported at Requirement 14, external examiners have been given a new remit for
overall quality assurance with access to all aspects of the examinations. They did not
actively participate in the assessing of students anymore.
Written papers were reviewed by more than one external examiner with time built into the
schedule to review the assessment of coursework. This would have been particularly
beneficial as it was found one of the written papers had been standard-set too high.
However, the School did not act on the feedback (detailed at Requirements 15 and 23).
External examiners are included in monitoring the progress routes through Year 1 to Year
4, and an external examiner scrutinised the student sign-up meeting for final
examinations. The inspectors were once again informed by the external examiners that
they felt the standard of the presentation cases seen at the School was equivalent and
comparable to other institutions. Students had prepared well with appropriate cases for
assessment.
Requirement 23: Assessment must be fair and undertaken against clear criteria.
Standard setting must be employed for summative assessments (Requirement revised
from Not Met to Partly Met)
The inspection panel indicated in the 2012/13 report that they could not determine to their
satisfaction, the rigour and defensibility of the assessment criteria outlined in the School
documentation and within their findings on the inspection.
Three actions were recorded in regards to the requirement in the 2012/13 inspection report:
i. The various assessment grading schemes and current style of intention marking must be reevaluated. There must be a clear model for how each area of student attainment is combined
into an overall grade which is underpinned with clear grade descriptors. The criteria for
progression must be understood by staff and students.
ii. Standard setting for summative assessments must be more explicit and clearly defined.
iii. The discussion during ratification of final grades at the examination board must be more
rigorous and open. Consideration should be given to the complexity of converting marks and
whether some students are disadvantaged by the rubric used to finalise grades.
The inspection panel was pleased to see that the School has a made a positive start to the
31

review of its assessment strategy. As outlined in earlier Requirements, the
Assessment/Examinations Group has taken on overall responsibility for the area. With input
from Year Leads and other senior staff, the group will be considering the grading scheme,
combination of grades and the application of intention marking in the A-E scale used outside of
LIFTUPP. It is appreciated that this will take some time to review, as the School reflects on the
best range of assessments to suit the overall competency based structure of the programme.
Standard setting for summative assessments was more explicit and defined. There was a
process for reviewing the Multiple-Choice Questions (MCQ) question bank within LIFTUPP. A
Theme Lead will be tasked to review subject specific questions and be able to change or reject
any which are judged not appropriate. Once agreed, the questions are standard-set using the
Angoff system. Short Answer Question papers (SAQ) are also standard-set using Angoff,
though this is undertaken outside of LIFTUPP.
This year, all written papers were submitted to the external examiners in advance. Further
input was subsequently required during the year five final examination diet where the external
examiners were asked to provide an independent review of the standard set pass mark. The
inspection panel accepted this was an appropriate action.
The inspectors noted that an external examiner had commented on the initial pass mark for the
written paper. The matter was not investigated by the School and might have been rectified in
advance of the final examinations had it been. In addition, an unseen clinical scenario had to
be changed as it had already been used in a written paper. Again, this oversight had already
been reported to the School by an external examiner and was not followed up. It was also
agreed that a more comprehensive blueprinting exercise should have been undertaken when
planning the assessments, which would have identified the same question overlapping two
components of the examinations.
Summative Objective Structured Clinical Examinations (OSCES) are run through years 2 to 4.
These are standard set once again using the Angoff method with a new observer sheet to only
allow for marks as dictated by the relevant station. Data is checked with a regression analysis.
The Assessment/Examinations Group are currently considering the potential benefits of
changing the grading to a global scoring system.
The inspection panel felt that the descriptors used for the Unseen cases could be clearer.
There was an A-E grade scale but also a criteria given for Honours, Distinction and Passes as
well, which might have confused the awarding of grades on occasions. As mentioned in
Requirement 21, there were no marking descriptors for presentation cases, which is something
that should be developed to help standardise the questions being asked by the examiner
teams.
The inspection panel once again observed the collation of intention marking into a final overall
grade at the examination board. The guide for determining overall marks combined the three
components of the final examination – unseen case scenario, presentation cases, and a
combined mark for the MCQ and SAP written papers – into a final grade. The marking scheme
for each element was A-E with the School rubric translating the marks into an overall A, B, C
for a pass and D or E for a fail.
The process for combining the three components within the A to E grading scheme remains
confusing. The inspectors are still not satisfied with the clarity of the amalgamation and
strongly believe the use of the rubric to convert the marks is not modern best practice in
assessment methodology. It was concluded that for all the depth of work being undertaken to
improve the standard setting of the examinations, the benefits of the statistical calibration is
somewhat lost within the second, less coherent round of translation and possible
compensation. In addition, at the high end of the scale, poor grades were hidden by the
32

compensation process and students could end up with potentially ‘commendation’ or ‘honours’
which were not appropriate. The inspectors wish to see the practice reviewed by the
Assessment/Examinations Group at the earliest opportunity.
Ultimately, the inspection panel was reassured by the work being done by the
Assessment/Examinations Group. It has evidenced a commitment to improving the overall
clarity of the School’s assessment strategy with a better focus on how to ensure assessments
are valid and reliable. Further developments are still needed, particularly in regards to the
overall combination of grades, the clarity of grade descriptors, examination blueprinting, and
attention to detail when considering feedback from external examiners.
The inspectors will review the progress in this area through the GDC annual monitoring
exercise.
Requirement 24: Where appropriate, patient/peer/customer feedback should
contribute to the assessment process (Requirement revised from Not Met to Partly
Met)
In 2012, the School indicated there was a broad range of reporting mechanisms cited as
potential paths to receive feedback from patients. However, the inspectors found no evidence
for the information being centrally managed and contributing to the assessment process.
One action was recorded in regards to the requirement in the 2012/13 inspection report:
The School must continue to develop its policy on patient feedback and explore how it might
contribute to assessments.
The inspectors saw evidence that the School has started to review how patient feedback
might contribute to the assessment process. The inspectors were told that the School has
looked at the Trust based patient feedback activity and systems used within Outreach
clinics, but these tended to be related to service provision and patient experience rather than
student performance.
It was seen that LIFTUPP has a section for patient feedback and feedback from Dental
Nurses, which could also be a valuable source of information. How best to incorporate these
facilities are currently being discussed at staff training days.
The inspection panel was mindful that this is an area that several Schools are still
developing, and Manchester is now working towards fulfilling the Requirement. It was
thought that senior staff should continue to evaluate where patient feedback can contribute
to the assessment process and start considering the matter within the appropriate
committees.
Requirement 25: Where possible, multiple samples of performance must be taken
to ensure the validity and reliability of the assessment conclusion (Requirement
remains Partly Met)
The inspection panel saw evidence that the School are beginning to adopt an assessment
strategy which brings together various components to produce robust, triangulated final
decisions. Multiple samples of student performance had been taken and the inspectors were
eventually satisfied of the reliability of the assessment conclusions.
Once again, further assurance of student attainment in their competencies was required by the
inspection panel. This was due to LIFTUPP data not always tallying with what was found on
CEDAR. Paper records were reviewed and the inspectors were satisfied that there had been
33

suitable coverage of assessment.
As detailed in earlier Requirements, the Assessment/Examinations Group are reviewing
several aspects of the assessment structure. It was also evident that the CEDAR and LIFTUPP
systems have started to become more embedded in the programme. The inspectors felt that
the School has an opportunity to build on these positive developments.
To take advantage of the progression data that will now be available, a round of assessment
blueprinting would be highly beneficial and could be incorporated with the mapping to the
learning outcomes in Preparing for Practice. This would provide ready access to multiple
samples of performance to support overall assessment decisions. The inspectors also agreed
that the accuracy of the performance data providing the assessment samples needs to be
more robustly checked. CEDAR and LIFTUPP are separate systems with no function for the
databases to cross-reference the recordings in one system with the other. The School must
ensure there are protocols in place that samples the accuracy and reliability of the information
being used.
Requirement 26: The standard expected of students in each area to be assessed
must be clear and students and staff involved in assessment must be aware of this
standard (Requirement revised from Not Met to Partly Met)
In the 2012/13 GDC report, the inspection panel had not been assured that students
understood the assessment strategy and were unable to identify what the School
considered a minimum level of student clinical experience.
At the re-inspection, the inspectors felt that the student groups were more confident in
their knowledge of what would be expected of them. They were pleased to find that a
Student’s Guide to Assessment had been published this year. The document has been
created by Assessment/Examinations Lead and provides an excellent reference for
students to see how they will be assessed over the whole five years of the programme. It
includes details of examination formats, when they occur, and whether they are formative
or summative.
As outlined in earlier Requirements, there remains a number of areas within the
assessment strategy that still requirement improvement but the inspectors were
impressed with the amount of hard work that has already been done. Staff appeared to
have more confidence in how the programme was operating on a strategic level under the
new management framework. There was evidence of a better distribution of expertise
amongst the committees, which has fed into the work being done by the
Assessment/Examinations Group. The inspectors are confident the assessment strategy
will be improved and strengthened with a comprehensive schedule of review and quality
assurance.

Actions
Req.
Number
16/25

Actions for the provider

(i)

Due Date
(if applicable)

The School must develop the SDR meetings and
consider a formal policy on the number of meetings
required per year and whether their recording would
be an appropriate requirement for sign-up rather than
something for noting
34

GDC Annual
Monitoring
2015

19

(ii)

The School must continue to review its assessment
structure to ensure a clear progression pathway can
be audited. There must be an overall strategy for how
each component of the programme fits together to
produce final assessment decisions, particularly on a
student’s clinical ability. Assessment decision points
must be openly and robustly evidenced.

GDC Annual
Monitoring
2015

(iii)

The School must continue to improve the monitoring
and recording of students achieving clinical
competencies. There must be a clearly defined policy
for when and how students are assessed in these
skills, which must be developed with an accurate
central management system to track student
progress.

GDC Annual
Monitoring
2015

(iv)

The School must complete a comprehensive
blueprinting of their assessment strategic to illustrate
the achievement of learning outcomes within the
programme.

GDC Annual
Monitoring
2015

(v)

The School should consider whether it might be
appropriate to introduce some aspect of practical
clinical dentistry to the final examinations.

GDC Annual
Monitoring
2015

(i)

The School must continue to review student
achievement of clinical competencies. The review
must include:
(a) The development of a formal policy for the
achievement of clinical competencies that
outlines where and how the tests are undertaken,
what the assessment are standard set against,
and how assessment calibration is maintained
across the School and Outreach sites.
(b) Clear guidance on how many times a student has
to complete a procedure before they can indicate
they feel ready to be tested.

GDC Annual
Monitoring
2015

GDC Annual
Monitoring
2015

(c) Between CEDAR and LIFTUPP, there must be
full and accurate record of a student’s clinical
exposure and a clear indication for how the
continuous clinical assessment has led up to
achievement of competencies.

GDC Annual
Monitoring
2015

(d) The School must consider the distribution of
competencies between the years. Consideration
must be made of the benefits of a more even
spread of competencies between the years of the
programme.

GDC Annual
Monitoring
2015

35

20

(i)

The School must continue to develop the
GDC Annual
engagement of students with reflection. There should Monitoring
be more clarity about how self-reflection is evaluated 2015
and used to influence assessment and/or progression
decisions.

(ii)

CEDAR and LIFTUPP offer the potential for feedback
to be well targeted and extensive. The School should
continue to explore maximising these elements of the
systems.

(i)

The School must ensure that examiners have the
most appropriate experience and background for
the areas of dentistry they are assessing.

(ii)

The School must develop its training for
examiners and ensure that a consistent
approach is adapted by each team of assessors.
Particular attention must be paid to the use of
radiographs during the examinations.

GDC Annual
Monitoring
2015

(i)

The School must develop marking descriptors
for presentation cases.

GDC Annual
Monitoring
2015

(ii)

Further consideration must be given to the
complexity of converting marks at the
examination board meeting, and whether some
students are disadvantaged by the rubric used to
finalise grades.

21

GDC Annual
Monitoring
2015

GDC Annual
Monitoring
2015

23

24

GDC Annual
Monitoring
2015

The School must continue to develop its policy on patient
feedback and explore how it might contribute to assessments.

GDC Annual
Monitoring
2015

The School must develop protocols for the regular sampling of
the accuracy and reliability of the information being held on the
CEDAR and LIFTUPP systems.

GDC Annual
Monitoring 2015

25

36

Standard 4 – Equality and diversity
The provider must comply with equal opportunities and discrimination legislation and
practice. They must also advocate this practice to students
Requirements
Met Partly Not
met
met
27. Providers must adhere to current legislation and best practice
guidance relating to equality and diversity



28. Staff will receive training on equality and diversity,
development and appraisal mechanisms will include this *



29. Providers will convey to students the importance of
compliance with equality and diversity law and principles of
the four UK Nations both during training and after they begin
practice *



* = Requirement has been revised from the 2012/13 report
GDC comments
Requirement 27: Providers must adhere to current legislation and best practice
guidance relating to equality and diversity (Requirement remains Met)
The University equality and diversity policy was once again noted. The document sets out a
commitment to promoting equality of opportunity and embracing diversity. There was policy
coverage for disability, respect and dignity, and a student complaints procedure was noted. No
incidents concerning an equality and/or diversity issue, either with staff or students, had been
recorded.
Staff and students showed a good awareness of equality and diversity issues and their
responsibility to uphold current best practice in the area. Standard NHS polices were in
operation within the dental hospital and at outreach placements, which is now monitored by the
Outreach Teachers Group.
Requirement 28: Staff will receive training on equality and diversity, development and
appraisal mechanisms will include this (Requirement revised from Partly Met to Met)
The 2012/13 inspection report noted that staff received Equality and Diversity training
from a range of sources but a record of the respect awards was not held centrally by the
School. Plans were being put in place to introduce such a system and link it up with staff
annual appraisals.
One action was recorded in regards to the requirement in the 2012/13 inspection report:
The School must continue to develop its plans to incorporate a review of equality and diversity
training in staff appraisals.
The inspection panel was informed that all staff are expected to complete appropriate Equality
and Diversity training. The UPC has agreed that annual staff appraisals will include a check on
relevant E&D training. This will form part of staff PDR and recorded on a central database.
Anyone who has student contact will have annual the online training including part-time staff,
NHS consultants, and outreach.

37

E&D training is also included in an assurance with the School’s annual learning and teaching
contract with the four NHS Trusts that operate the outreach placements.
Requirement 29: Providers will convey to students the importance of compliance with
equality and diversity law and principles of the four UK Nations both during training
and after they begin practice (Requirement revised from Partly Met to Met)
In the 2012/13 inspection report, the inspection panel was directed to one intended learning
outcome for this area. It was formatively assessed in on-going staff assessment through each
year of the programme. There was also a suggestion that summative assessment may occur
during OSCE examinations. The inspectors were unsure why the School only indicated that a
summative assessment may occur and felt it was entirely appropriate for such an area to
always have some form of summative assessment.
One action was recorded in regards to the requirement in the 2012/13 inspection report:
The School must consider whether the taught component for equality and diversity should be
expanded. Summative assessment in this area should become standard within the programme.
The School indicated that all undergraduate students are expected to complete an online Elearning package entitled “Quality, Diversity and Human Rights.” This is the same NHS package
that is completed by all the Consultants in the Dental Hospital as part of their Corporate
Mandatory.
Completion of all E-learning packages has become a requirement for sign-up to year on year
progression and final examinations. The School also has various EBL sessions that contribute
to formative assessment in this area. The inspectors felt this showed good progress though
further development would still be beneficial. There was some concern that a student might be
able to perform poorly in the formative assessments yet still progress as the e-learning
examination appears to have some element of rote learning.
Staff and students once again showed a good awareness of equality and diversity and their
responsibility to comply with the relevant laws. Students appreciated there would be
differences in legislation from country to country within the UK.
Actions
Req.
Actions for the provider
Number

Due Date
(if applicable)

29
The School should continue to consider whether the taught
GDC Annual
component and summative assessment for equality and diversity Monitoring 2015
should be further expanded.

38

Summary of Actions
Req.
Number

Action

Observations

Due date

Response from Provider
1
All tutors must be mindful of the periods of time
between a student learning skills in a pre-clinical
environment, and the first opportunity for them to
practise the procedure on a patient in clinic. The
School should introduce formal expiry dates to the
achievement of skills tests by students. There should
be a clear policy on revocation and reinstatement
following any further assessment.

Through the Assessment and Examinations
Group (AEG) and Undergraduate Programme
Committee (UPC), core skills will be identified.
Competency exercises in each of these skills will
be repeated annually. Failure to complete these
will stop progression.

By academic year

The School should continue its commitment to staff
training and calibration for the issuing of
professionalism cards to ensure the system remains
fair and reliable.

Staff will be requested to undertake the
calibration exercises annually as part of their
annual Performance and Development Review.

With immediate

2015-16.

8

effect.

9

(i)

The School must continue to establish its
This continues and the appropriate documents
revised management framework and
will be provided.
provide relevant committee minutes in their
response to the GDC annual monitoring
exercise next year

(ii)

The School must make the mapping of the
programme to the learning outcomes in the
GDC document Preparing for Practice a
matter of priority

Ongoing

Completed
This work has already been carried out. The
Inspectors were invited to see the mapping on a
database, however, as far as I am aware they did
not wish to.
The mapping occurred during the last academic
39

year as described to the Inspectors and was
available for them to see. All year leads were
then asked to confirm that each part of the
course conformed to Preparing for Practice.
Because of the Intended Learning Outcomes that
The Manchester Dental Programme has and how
they mapped across to Preparing for Practice, we
are content that our students are currently being
produced against Preparing for Practice so that
this will have been fully embedded by summer
2016.
10

The School should include minutes from the Outreach
Teachers Group and details of staff training sessions
involving Outreach staff, in their response to the GDC
annual monitoring exercise next year

This work is ongoing and will be reported on. BSc
Outreach tutors are now also included in the
Outreach Teachers Group.

Ongoing

13

(i)

The School must include details of the
The date has yet to be set by Faculty but will be
Periodic Review scheduled to be completed done as soon as reasonably possible and will
in the 2014/15 academic year in their
be reported on in the annual monitoring
response to the GDC annual monitoring
exercise.
exercise next year

Ongoing

Ongoing
(ii)

The School must provide evidence for
where consideration has been made in
having closer ties with the University
Faculty. This should be included in their
response to the GDC annual monitoring
exercise next year

This has been considered by the
Undergraduate Programme Committee and
there is now a standing report from the School
of Dentistry as part of Faculty Undergraduate
Teaching and Learning Committee. The
appropriate minutes will be provided in the
annual monitoring exercise, however, it is worth
noting that there is a move to devolve more
responsibility for administrative and
management processes to School level within
40

Faculty.

15

The School should include minutes from the
Assessment/Examination Group in their response to
the GDC annual monitoring exercise next year

These will be included in the annual monitoring
exercise next year.

Annual
monitoring
exercise,
ongoing

16/25
(i)

The School must develop the SDR
meetings and consider a formal policy on
the number of meetings required per year
and whether their recording would be an
appropriate requirement for sign-up rather
than something for noting

The SDR meetings will take place for every
student in each term under the chair of each
Year Lead, they will be recorded and form part
of the sign-up process.

Within the next 6
months.

(ii)

The School must continue to review its
assessment structure to ensure a clear
progression pathway can be audited.
There must be an overall strategy for how
each component of the programme fits
together to produce final assessment
decisions, particularly on a student’s
clinical ability. Assessment decision points
must be openly and robustly evidenced.

This work is ongoing. There will be a
summative assessment at the end of each
relevant clinical skills course, double marked
with referenced criteria. Students failing will be
referred to the Health and Conduct Committee
for an action plan.

By academic
year 2015-16

(iii)

The School must continue to improve the
monitoring and recording of students
achieving clinical competencies. There
must be a clearly defined policy for when
and how students are assessed in these
skills, which must be developed with an
accurate central management system to
track student progress.

See above, this will be recorded through the
CEDAR system and use made of the
Assessment Handbook written by the AEG.

By the end of the
academic year

41

(iv)

The School must complete a
comprehensive blueprinting of their
assessment strategic to illustrate the
achievement of learning outcomes within
the programme.

(v)

The School should consider whether it
might be appropriate to introduce some
aspect of practical clinical dentistry to the
final examinations.

This work is completed and relates to the
mapping of the ILOs with PfP. It will be reported
in the annual monitoring exercise.
AEG will constantly review the mapping to
ensure that ILOs are tested in a timely and valid
manner.

Ongoing

The School has considered this in the past and
will revisit the issue in collaboration with other By academic
Schools in the UK. At the moment we are content year 2015-16
that our IPCs demonstrate appropriate clinical
skills and that other assessments test other
clinical areas satisfactorily.
We question how meaningful an OSCE
simulation exam is at the stage of Finals,
particularly when the students are demonstrating
a full range of skills in both the Integrated
Presentation Cases and unseen examination.
Indeed, the School has considered this at
Assessment and Examination Group and
Undergraduate Programme Committee level, and
made the decision not to have an OSCE as part
of Finals as it was felt that the allocated time per
station in OSCE, does not allow many aspects of
clinical dentistry to be assessed. The summative
clinical skills test will NOT be observing “a filling”
under the exam condition but we were planning
to include one indirect restoration and one RCT
in a single diet of the exam, which are too
complex and too time-consuming to be assessed
using OSCE. An OSCE will still remain as part of
the yearly examinations throughout the rest of the
course.

42

19

(i)

The School must continue to review
student achievement of clinical
competencies. The review must include:
(a) The development of a formal policy for
the achievement of clinical
competencies that outlines where and
how the tests are undertaken, what the
assessments are standard set against,
and how assessment calibration is
maintained across the School and
Outreach sites.

AEG continues to monitor this activity and are
considering formulating clearer descriptors for
the assessments. The use of videos and away
day sessions addresses the issue of examiner
calibration.

(b) Clear guidance on how many times a
student has to complete a procedure
before they can indicate they feel
ready to be tested.

This is and has always been intended to be;
student led, under the advice of the relevant
member of staff.

(c) Between CEDAR and LIFTUPP, there
must be full and accurate record of a
student’s clinical exposure and a clear
indication for how the continuous
clinical assessment has led up to
achievement of competencies.

The AEG discussed this and felt that by
implementing the suggested plans in 19 i.a), it
will be a matter of demonstration of
competency in all the skill sets to allow a
student to progress; therefore the matter of
“number of attempts” will no longer play a role.

Ongoing

In addition to this, AEG is piloting the
introduction of mini-cases and clinical portfolios
that allows a more structured way of recording
the core competences. This will be extended to
all the BDS years upon a successful experience
of the current pilot. It is likely that the skills
would be marked using the 6-point scale and
therefore the group will consider setting a mark
as the minimum requirement for each skill
tested. This will be subject to further discussion
by the group when implementing the portfolio
system in future

43

Ongoing

Ongoing

(d) The School must consider the
distribution of competencies between
the years. Consideration must be
made of the benefits of a more even
spread of competencies between the
years of the programme.

Clinical exposure is recorded through LIFTUPP
and competency acquisition through CEDAR. A
large number of competencies are tested in
Year 3 on a stand alone basis, the use of
portfolio based assessment currently being
piloted in Year 2, when appropriately evaluated
will address these issues if deemed to have
been successful.

By academic
year 2015-16

This work is currently part of a larger review
being undertaken by the AEG.
20

(i)

The School must continue to develop the
engagement of students with reflection.
There should be more clarity about how
self-reflection is evaluated and used to
influence assessment and/or progression
decisions.

The area of reflection is currently under
development, students will be required to
complete 2 exercises prior to their SDR
meetings, which will inform those meetings.

Ongoing, within
the next 6
months

(ii)

CEDAR and LIFTUPP offer the potential
for feedback to be well targeted and
extensive. The School should continue to
explore maximising these elements of the
systems.

This work is ongoing, involving AEG and UPC.

Ongoing

(i)

The School must ensure that
examiners have the most appropriate
experience and background for the
areas of dentistry they are assessing.

This area has been reviewed and in future will
involve more of our part time GDP staff.

By 2015 diet of
Finals

(ii)

The School must develop its training
for examiners and ensure that a
consistent approach is adapted by
each team of assessors. Particular
attention must be paid to the use of

We continue to require examiners to complete
our online and face to face training and
calibration and the use of radiographs has been
discussed at AEG.

By 2015 diet of
Finals

21

44

radiographs during the examinations.

The AEG will also use “common scenarios” for
the calibration of Seen Case Scenario examiners.

(i)

The School must develop marking
descriptors for presentation cases.

These descriptors have been developed and
were used in 2014 following comments from
internal and external examiners.

(ii)

Further consideration must be given
to the complexity of converting marks
at the examination board meeting,
and whether some students are
disadvantaged by the rubric used to
finalise grades.

23

24

By 2015 diet of
Finals

We appreciate the complexity of the examination By 2015 diet of
rubric, this has been removed and a simpler Finals
system will be used this summer.

The School must continue to develop its policy on
patient feedback and explore how it might contribute
to assessments.

Patient feedback is being sought both in the In place
Dental Hospital and Outreach and will form part
of the student’s portfolio for discussion at SDR
meetings.

The School must develop protocols for the regular
sampling of the accuracy and reliability of the
information being held on the CEDAR and LIFTUPP
systems.

Data on LIFTUPP is generated by student,
verified by tutor and acknowledged by the
student. The QA is quite tight and there is no
need to check the accuracy; however, to check
the reliability, data has to be sampled by 1 or 2
senior members of staff to identify doves and
hawks. This is currently being explored by
AEG.

25

Both systems are independent and record
different things; CEDAR records the clinical
competencies, red and yellow cards, absence,
and meetings with Academic Advisors etc.
LIFTUPP also records clinical alerts, which can
on consideration become red or yellow cards;
45

By the end of the
current
academic year

however, LIFTUPP’s main role is the recording of
clinical activity and progress through assessment
of that activity. This data was reviewed as part of
sign-up in May and because both systems are
relatively recent in implementation, it was
necessary to refer to previous paper based
systems to capture all of a student’s experience
and progress. We anticipate that we will be fully
electronic by summer 2016 so the need for both
paper and electronic records will no longer exist.

29

The School should continue to consider whether the
taught component and summative assessment for
equality and diversity should be further expanded.

This will be considered by UPC, however, the
University and Faculty consider that our
commitment to equality and diversity and our
engagement with our E and D staff is very high.
AEG will ensure that E&D will be part of the
blueprint of the summative exams.

Ongoing

Observations from the provider on content of report
We thank the Inspection Panel for their time and their efforts during the inspection. We are delighted that they have deemed us as sufficient.
We are glad that the Panel have clearly appreciated the efforts that The School has made over the past 18 months since the previous
inspection, particularly in terms of our outreach delivery and assessment strategy and in terms of the number of Requirements that they now
feel that we have met. In terms of those Requirements still Partly Met, I invite the Panel to consider our Action Plan, which addresses all of
these issues.
With regards to Requirement 21 which has slipped to Partly Met, this has been addressed as a matter of priority by the Assessment and
Examinations Group with the action as listed in our formal response.

46

Recommendations to the GDC
The inspectors recommend that this qualification is sufficient for holders to apply for registration as a dentist with the General Dental Council.

Instructions to the School
To compile an action plan for the implementation of all actions outlined in report and submit the document to the GDC within six weeks of
receipt of the finalised report.

47

